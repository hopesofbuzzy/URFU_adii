{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hopesofbuzzy/URFU_adii/blob/main/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B8/11/06_PromptEng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c23371a-3f67-4e0d-be8d-a69967daa3a4",
      "metadata": {
        "id": "5c23371a-3f67-4e0d-be8d-a69967daa3a4"
      },
      "source": [
        "# Работа с LLM GigaChat"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e3eaae1-b539-45c3-8432-8b1852cf020e",
      "metadata": {
        "id": "3e3eaae1-b539-45c3-8432-8b1852cf020e"
      },
      "source": [
        "[GigaChat](https://developers.sber.ru/docs/ru/gigachain/tools/python/gigachat) — это Python-библиотека для работы с `REST API GigaChat`. Она является частью [`GigaChain`](https://github.com/Scicommunity/gigachain) и входит в состав `langchain-gigachat` — партнерского пакета opensource-фреймворка [`LangChain`](https://www.langchain.com/).\n",
        "\n",
        "[Библиотека](https://gitverse.ru/ai-forever/gigachain) управляет авторизацией запросов и предоставляет все необходимые методы для работы с `API`. Кроме этого она поддерживает:\n",
        "\n",
        "* обработку потоковой передачи токенов;\n",
        "* работу с функциями;\n",
        "* создание эмбеддингов;\n",
        "* работу в синхронном или в асинхронном режиме.\n",
        "\n",
        "СМ. Также\n",
        "* [туторилаы по `GigaChat`](https://giga.chat/help/tutorials)\n",
        "* [примеры работы с библиотекой `GigaChat`](https://github.com/ai-forever/gigachat/tree/main/examples)\n",
        "* [некоторые неофициальные туториалы по `GigaChat`](https://github.com/trashchenkov/gigachat_tutorials)\n",
        "* [репозиторий `GigaChain`](https://gitverse.ru/ai-forever/gigachain)\n",
        "* [`langchain` tutorials](https://github.com/gkamradt/langchain-tutorials)\n",
        "* Статьи на Хабр [тут](https://habr.com/ru/articles/906584/), [тут](https://habr.com/ru/companies/sberbank/articles/941340/) и [тут](https://habr.com/ru/companies/sberdevices/articles/794773/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66f7506b-30a6-4db2-a534-c722482c3d5c",
      "metadata": {
        "id": "66f7506b-30a6-4db2-a534-c722482c3d5c"
      },
      "source": [
        "Для получения доступа к [GigaChat](https://developers.sber.ru/docs/ru/gigachain/tools/python/gigachat) нужно пройти [авторизацию тут](https://developers.sber.ru/studio/login) или другим [способом авторизации](https://developers.sber.ru/docs/ru/gigachain/tools/python/gigachat#sposoby-avtorizatsii)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gigachat\n",
        "!pip install ddgs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OpshkKS5W2L",
        "outputId": "f7b63fd3-f8a2-40c3-e562-28c6e16ae981"
      },
      "id": "3OpshkKS5W2L",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gigachat in /usr/local/lib/python3.12/dist-packages (0.1.43)\n",
            "Requirement already satisfied: httpx<1 in /usr/local/lib/python3.12/dist-packages (from gigachat) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1 in /usr/local/lib/python3.12/dist-packages (from gigachat) (2.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1->gigachat) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (0.4.2)\n",
            "Requirement already satisfied: ddgs in /usr/local/lib/python3.12/dist-packages (9.10.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from ddgs) (8.3.1)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (0.15.0)\n",
            "Requirement already satisfied: lxml>=4.9.4 in /usr/local/lib/python3.12/dist-packages (from ddgs) (6.0.2)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
            "Requirement already satisfied: fake-useragent>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (2.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.2.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
            "Requirement already satisfied: socksio==1.* in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c75744f8-59dd-429a-94b7-442f4f06fc7e",
      "metadata": {
        "id": "c75744f8-59dd-429a-94b7-442f4f06fc7e"
      },
      "outputs": [],
      "source": [
        "from gigachat import GigaChat\n",
        "from gigachat.models import Chat, Function, FunctionParameters, Messages, MessagesRole\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "18c08934-96f1-44a3-8a35-ed7068751302",
      "metadata": {
        "id": "18c08934-96f1-44a3-8a35-ed7068751302"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from ddgs import DDGS\n",
        "\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39d4ffbd-5a47-4c5f-b676-10b6a2052c99",
      "metadata": {
        "id": "39d4ffbd-5a47-4c5f-b676-10b6a2052c99"
      },
      "source": [
        "Прочитаем токен"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09fbec88-306d-44a4-9699-71df5cabc22d",
      "metadata": {
        "id": "09fbec88-306d-44a4-9699-71df5cabc22d"
      },
      "outputs": [],
      "source": [
        "token = open('authGigaChat.txt').read().strip()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client_id = userdata.get('SBER_ID')\n",
        "secret = userdata.get('SBER_SECRET')\n",
        "auth = userdata.get('SBER_AUTH')\n",
        "\n",
        "import base64\n",
        "credentials = f\"{client_id}:{secret}\"\n",
        "print(credentials)\n",
        "encoded_credentials = base64.b64encode(credentials.encode('utf-8')).decode('utf-8')\n",
        "\n",
        "\n",
        "encoded_credentials == auth"
      ],
      "metadata": {
        "id": "v3n9TJfP9xxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef9f0c5-d571-4116-bb70-6260cdfd2223"
      },
      "id": "v3n9TJfP9xxJ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "019a6bdb-607f-745f-aafe-84a8fed0da0b:a2c04575-4ef1-480e-954e-afd1d3ac34ce\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49629be5-85e0-4639-ab6c-83f09b35491c",
      "metadata": {
        "id": "49629be5-85e0-4639-ab6c-83f09b35491c"
      },
      "source": [
        "Проверим что все работает для этого попробуем задать простой вопрос __пользователя__ к\n",
        "__модели__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "259577cb-1edb-4bb1-b763-70bb0213a696",
      "metadata": {
        "id": "259577cb-1edb-4bb1-b763-70bb0213a696"
      },
      "outputs": [],
      "source": [
        "MESSAGE = \"Дай определение и Расскажи в 3 коротких пунктах об особенностях prompt engineering, \""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "1MTTWBhs_ycf",
        "outputId": "1f3a5e02-9231-4b27-d5e8-ac8dc4aacd98"
      },
      "id": "1MTTWBhs_ycf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "GigaChatSyncClient.get_models() missing 1 required positional argument: 'self'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4020771973.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGigaChat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: GigaChatSyncClient.get_models() missing 1 required positional argument: 'self'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67334fd8-a4a4-4109-b516-78acd9387a21",
      "metadata": {
        "id": "67334fd8-a4a4-4109-b516-78acd9387a21",
        "outputId": "2e38f88d-4ceb-47a2-a4e7-380614d19db1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GigaChat\n",
            "GigaChat-2\n",
            "GigaChat-2-Max\n",
            "GigaChat-2-Pro\n",
            "GigaChat-Max\n",
            "GigaChat-Max-preview\n",
            "GigaChat-Plus\n",
            "GigaChat-Pro\n",
            "GigaChat-Pro-preview\n",
            "GigaChat-preview\n",
            "Embeddings\n",
            "Embeddings-2\n",
            "EmbeddingsGigaR\n",
            "GigaEmbeddings-3B-2025-09\n"
          ]
        }
      ],
      "source": [
        "with GigaChat(credentials=authverify_ssl_certs=False) as giga:\n",
        "    for model in giga.get_models().data:\n",
        "      print(model.id_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with GigaChat(credentials=auth, model=\"GigaChat-2\", verify_ssl_certs=False) as giga:\n",
        "    response = giga.chat(MESSAGE)\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aers5cZ5B2W8",
        "outputId": "f707524f-5f4b-48b0-bb17-4084aea401b2"
      },
      "id": "Aers5cZ5B2W8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Prompt Engineering (инженерия запросов)** — методология составления чётких, лаконичных и понятных инструкций для нейросетей, направленная на получение точного и качественного результата от модели ИИ.\n",
            "\n",
            "### Особенности Prompt Engineering:\n",
            "\n",
            "1. **Сжатость формулировок:**   \n",
            "   Короткость и конкретика запроса позволяют нейросети лучше понимать цель и быстрее выдавать нужный результат.\n",
            "   \n",
            "2. **Использование структуры и контекста:**  \n",
            "   Четкая структура подсказки и включение контекста помогают избежать двусмысленности и уточняют ожидания модели относительно типа желаемого ответа.\n",
            "\n",
            "3. **Гибкость в интерпретации:**  \n",
            "   Инженеры запросов используют различные техники уточнения (например, добавление тегов, директив и пояснений), чтобы повлиять на поведение нейросети и получить наиболее подходящий отклик.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f384aab6-a101-4a72-a7a3-ebb1f334d513",
      "metadata": {
        "id": "f384aab6-a101-4a72-a7a3-ebb1f334d513"
      },
      "source": [
        "----------------------------------------------------\n",
        "\n",
        "В Использованной модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72b55097-2e25-4ba5-bcd8-55147dc9d1e0",
      "metadata": {
        "id": "72b55097-2e25-4ba5-bcd8-55147dc9d1e0"
      },
      "source": [
        "|Параметр|Обязательный|Описание|\n",
        "|---|---|---|\n",
        "|`credentials`|да|Ключ авторизации для обмена сообщениями с `GigaChat API`. Ваш токен доступа из личного кабинета Сбера.|\n",
        "| | |Ключ авторизации содержит информацию о версии `API,` к которой выполняются запросы. Если вы используете версию `API` для ИП или юрлиц, укажите это явно в параметре `scope`|\n",
        "|`verify_ssl_certs`|нет|Отключение проверки `ssl`-сертификатов.|\n",
        "| | | |\n",
        "| | |[Для обращения к `GigaChat API` нужно установить корневой сертификат НУЦ Минцифры.](https://developers.sber.ru/docs/ru/gigachat/certificates)|\n",
        "| | | |\n",
        "| | |Используйте параметр ответственно, так как отключение проверки сертификатов снижает безопасность обмена данными|\n",
        "|`scope`|нет|Версия `API`, к которой будет выполнен запрос. По умолчанию запросы передаются в версию для физических лиц. Возможные значения:|\n",
        "| | |`GIGACHAT_API_PERS` — версия `API` для физических лиц;|\n",
        "| | |`GIGACHAT_API_B2B` — версия `API` для ИП и юрлиц при работе по предоплате.|\n",
        "| | |`GIGACHAT_API_CORP` — версия `API` для ИП и юрлиц при работе по постоплате.|\n",
        "|`model`|нет|необязательный параметр, в котором можно явно задать модель `GigaChat`. Вы можете посмотреть список доступных моделей с помощью метода `get_models()`, который выполняет запрос `GET /models`.|\n",
        "| | | |\n",
        "| | |[Стоимость запросов к разным моделям отличается. Подробную информацию о тарификации запросов к той или иной модели вы ищите в официальной документации](https://developers.sber.ru/docs/ru/gigachat/api/tariffs)|\n",
        "|base_url|нет|[Адрес API. По умолчанию запросы отправляются по адресу https://gigachat.devices.sberbank.ru/api/v1/, но если вы хотите использовать модели в раннем доступе, укажите адрес https://gigachat-preview.devices.sberbank.ru/api/v1](https://developers.sber.ru/docs/ru/gigachat/models/preview-models)|"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24704eb9-a627-4085-8242-6a4a3b8776af",
      "metadata": {
        "id": "24704eb9-a627-4085-8242-6a4a3b8776af"
      },
      "source": [
        "Также синтаксис выход модели - `markdown`, поэтому сделаем его более читаемым"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f74e41a-be15-4690-b439-4a0bf9ea1f63",
      "metadata": {
        "id": "9f74e41a-be15-4690-b439-4a0bf9ea1f63"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d6420c-d727-45aa-89a2-2379a852fd4f",
      "metadata": {
        "id": "17d6420c-d727-45aa-89a2-2379a852fd4f",
        "outputId": "8df99122-101b-4eb8-fd8e-a1853c101d72"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<blockquote>\n",
              "\n",
              "**Prompt Engineering (инжиниринг подсказок)** — это процесс тщательной разработки и настройки входной информации (подсказки), подаваемой модели машинного обучения (например, языковой модели), чтобы получить оптимальный результат выполнения поставленных задач.\n",
              "\n",
              "### Особенности Prompt Engineering:\n",
              "\n",
              "1. **Учет контекста**:  \n",
              "   Формулировка подсказки должна учитывать специфику поставленной задачи, включая тонкости формулировок, используемые термины и требуемый контекст.\n",
              "\n",
              "2. **Структурирование запроса**:  \n",
              "   Грамотная структура подсказки помогает модели эффективно понимать и обрабатывать запросы, снижая вероятность ошибок и улучшая качество результата.\n",
              "\n",
              "3. **Контроль выдачи**:  \n",
              "   Правильный выбор инструкций и шаблонов позволяет добиться нужной длины ответа, его точности и стилистики."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with GigaChat(credentials=token, verify_ssl_certs=False) as giga:\n",
        "    response = giga.chat(MESSAGE)\n",
        "    content = response.choices[0].message.content\n",
        "    display(Markdown(\"<blockquote>\\n\\n\"+content))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad6179e8-5d6b-4113-b673-d642dbfae6ea",
      "metadata": {
        "id": "ad6179e8-5d6b-4113-b673-d642dbfae6ea"
      },
      "source": [
        "______________________________________________________\n",
        "\n",
        "Перейдем к выбору моделей. Актуальный список моделей можно найти [тут](https://developers.sber.ru/docs/ru/gigachat/models). Модели могут отличатся качеством и разнообразием ответов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3206700-7371-493b-b20b-93c7a810d9f1",
      "metadata": {
        "scrolled": true,
        "id": "b3206700-7371-493b-b20b-93c7a810d9f1"
      },
      "outputs": [],
      "source": [
        "model = GigaChat(\n",
        "    model=\"GigaChat-2\",\n",
        "    credentials=auth,\n",
        "    verify_ssl_certs=False\n",
        ")\n",
        "\n",
        "\n",
        "# response = model.chat(MESSAGE)\n",
        "# content = response.choices[0].message.content\n",
        "# # print(content)\n",
        "# display(Markdown(\"<blockquote>\\n\\n\"+content))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e96d3c1-7b1e-41e5-98a6-8ed16772f6d2",
      "metadata": {
        "id": "0e96d3c1-7b1e-41e5-98a6-8ed16772f6d2"
      },
      "source": [
        "### Упражнения\n",
        "1. Предложите промпт, требующий знания информации на текущую дату, на дату несколько лет назад и на достаточно известное историческое событие, сравните и объясните результаты.\n",
        "2. Проверить качество результата запросов по категориям: математика, естественные науки, гуманитарные науки для разных моделей.\n",
        "3. Создайте небольшой диалог двух ИИ-персон"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebb17067-a6b8-4eef-b99e-32525d14c29b",
      "metadata": {
        "id": "ebb17067-a6b8-4eef-b99e-32525d14c29b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c126b203-a135-455f-b3e8-d4923ebb6fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Коронавирусная инфекция COVID-19 (вызываемая вирусом SARS-CoV-2) впервые была зафиксирована в конце декабря 2019 года в китайском городе Ухань провинции Хубэй. \n",
            "\n",
            "Первые случаи заражения связаны с рынком морепродуктов и живой птицы — предполагается, что источником инфекции могли стать животные. Вскоре после обнаружения заболевания оно быстро распространилось по всему миру, вызвав пандемию, объявленную Всемирной организацией здравоохранения 11 марта 2020 года.\n",
            "\n",
            "На сегодняшний день пандемия продолжает оставаться актуальной проблемой мировой медицины и общественного здравоохранения.\n"
          ]
        }
      ],
      "source": [
        "with GigaChat(credentials=auth, model=\"GigaChat-2\", verify_ssl_certs=False) as giga:\n",
        "  response = giga.chat(\"Когда случился Коронавирус\")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "DV2u3g6qB4_d"
      },
      "id": "DV2u3g6qB4_d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52e77a02-3307-4eaa-b9f1-9eedff40cea4",
      "metadata": {
        "id": "52e77a02-3307-4eaa-b9f1-9eedff40cea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "25a049f8-1ade-4972-ce08-67f52d782d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Объясни, что такое AI-agent?\n",
            "-----------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "AI-Agent (искусственный интеллектуальный агент) — это автономная система, способная действовать в окружающей среде самостоятельно, принимая решения и взаимодействуя с внешним миром согласно заданной цели или набору правил. Ключевые характеристики AI-агента включают:\n\n1. **Автономность**: агент действует независимо от человека, выполняя заранее запрограммированные или самообученные алгоритмы действий.\n   \n2. **Целевая ориентация**: агент имеет цель или набор целей, которые направляют его"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " поведение. Например, минимизировать затраты, максимизировать прибыль, достичь определённой точки пространства или получить доступ к ресурсам.\n\n3. **Интерактивность**: агент способен воспринимать окружение через сенсорную информацию (визуальные данные, звуковые сигналы, показания датчиков), анализировать её и реагировать соответствующим образом.\n\n4. **Адаптивность**: способность агента корректировать своё поведение на основе опыта взаимодействия с внешней средой, обучаясь новым стратегиям поведения и улучшая эффективность выполнения поставленных задач.\n\n5"
          },
          "metadata": {}
        }
      ],
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=\"Объясни, что такое AI-agent?\"\n",
        "        ),\n",
        "]\n",
        "\n",
        "payload = Chat(\n",
        "    messages=messages,\n",
        "    temperature=0.7,\n",
        "    max_tokens=100,\n",
        ")\n",
        "\n",
        "print(\"Объясни, что такое AI-agent?\")\n",
        "for role in [MessagesRole.ASSISTANT, MessagesRole.USER]:\n",
        "  with GigaChat(credentials=auth, model=\"GigaChat-2\", verify_ssl_certs=False) as giga:\n",
        "    response = giga.chat(payload)\n",
        "    payload.messages.append(Messages(role=role, content=response.choices[0].message.content))\n",
        "    print(\"-----------------\")\n",
        "    display(Markdown(response.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5be346c-4b50-498e-a6c2-397067ceed27",
      "metadata": {
        "id": "a5be346c-4b50-498e-a6c2-397067ceed27"
      },
      "source": [
        "\n",
        "# Роли и контекст запроса\n",
        "\n",
        "\n",
        "Более правиьно формулировать запросы (`payload`) к модели с использованием объекта типа `Chat`.\n",
        "`Chat` — это объект, описывающий весь чат-запрос к модели. Он содержит:\n",
        "* `messages` — список сообщений, представляющих историю диалога.\n",
        "* `temperature` — параметр, управляющий «творчеством» модели:\n",
        "    * Чем ближе температурак `0`, тем более детерминированный и предсказуемый ответ.\n",
        "    * Чем ближе температура к `1` (или выше), тем более случайный и разнообразный ответ.\n",
        "    * Например, значение `0.7` — баланс между креативностью и точностью.\n",
        "* `max_tokens` — ограничение на длину ответа модели (в токенах). Каждый токен приблизительно одно слово.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b1bd042-8ad1-474d-9d55-3c28608d685c",
      "metadata": {
        "id": "4b1bd042-8ad1-474d-9d55-3c28608d685c"
      },
      "outputs": [],
      "source": [
        "payload = Chat(\n",
        "    messages=[\n",
        "    Messages(role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        )\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_tokens=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5186bd1c-9c2f-4b34-b9dc-27792db222e9",
      "metadata": {
        "id": "5186bd1c-9c2f-4b34-b9dc-27792db222e9",
        "outputId": "48a08557-4e46-43b9-bcd6-4dd726a9bbad"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<blockquote>\n",
              "\n",
              "**Prompt Engineering (инженерия подсказок)** — процесс формирования запросов к искусственному интеллекту таким образом, чтобы получить наиболее точный, полезный и понятный результат от модели.\n",
              "\n",
              "### Особенности Prompt Engineering:\n",
              "1. **Четкость формулировки**: запросы должны быть ясными, лаконичными и точно отражающими желаемый результат.\n",
              "2. **Контекстуальность**: важно учитывать контекст задачи, чтобы подсказка учитывала специфику ситуации и помогала модели лучше понять задание.\n",
              "3. **Итеративность**: часто требует тестирования разных формулировок запроса и анализа результатов, чтобы найти оптимальную структуру подсказки."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = model.chat(MESSAGE)\n",
        "content = response.choices[0].message.content\n",
        "# print(content)\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c232cfc8-9407-4adf-8e44-cbac409f3fd7",
      "metadata": {
        "id": "c232cfc8-9407-4adf-8e44-cbac409f3fd7"
      },
      "source": [
        "-------------------------------------------------\n",
        "\n",
        "Сообщения в messages имеют роли (`role`), которые определяют, кто «говорит»:\n",
        "* `SYSTEM` — задаёт поведение модели. Это инструкция, невидимая пользователю, но влияющая на стиль и содержание ответов.\n",
        "Пример: «Ты полезный ассистент для тестирования ГигаЧата» — модель будет вести себя как помощник, ориентированный на тестирование.\n",
        "* `USER` — сообщение от пользователя (реальный вопрос или команда).\n",
        "* `ASSISTANT` — ответ модели (обычно добавляется автоматически после генерации).\n",
        "\n",
        ">История диалога формируется последовательным добавлением сообщений с разными ролями.\n",
        ">\n",
        "> Модель «помнит» контекст только в рамках одного запроса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64afdfe0-516b-49f9-8ac3-ed611e460959",
      "metadata": {
        "id": "64afdfe0-516b-49f9-8ac3-ed611e460959"
      },
      "outputs": [],
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.SYSTEM,\n",
        "            content=(\n",
        "                \"Ты полезный ассистент для тестирования ГигаЧата. Твоя задача отвечать студенту на учебные вопросы\\n\"\n",
        "                \"## Инструкция\\n\"\n",
        "                \"Ответ должен подходить студенту начальных курсов бакалавриата, изучающему технологии искусственного интеллекта\\n\"\n",
        "                \"## Формат ответа\\n\"\n",
        "                \"Текст и таблицы в формате markdown\\n\"\n",
        "            )\n",
        "        ),\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        ),\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cbd16f4-43d6-4dd8-aa33-c5831d4a482c",
      "metadata": {
        "id": "7cbd16f4-43d6-4dd8-aa33-c5831d4a482c",
        "outputId": "49eee02e-b4e2-4491-ea42-db18282a0fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\n**Определение Prompt Engineering**\nPrompt engineering — это процесс создания эффективных и целенаправленных входных данных (prompts) для моделей машинного обучения с целью получения желаемых результатов от нейросетевых систем.\n\n### Особенности Prompt Engineering:\n\n1. **Ясность и Конкретизация**\n   - Хорошо сформулированные prompts помогают модели точно понять задачу и избежать неоднозначности или неправильного понимания запроса.\n   \n2. **Структура и Форматирование**\n   - Использование структурированных форматов (например, шаблонов вопросов, инструкций или примеров) позволяет направлять модель к желаемому результату более эффективно.\n   \n3. **Контекст и Ориентация на Цель**\n   - Эффективный prompt учитывает контекст задачи и четко формулирует цель, что помогает модели сосредоточиться именно на необходимых аспектах проблемы."
          },
          "metadata": {}
        }
      ],
      "source": [
        "payload = Chat(\n",
        "    messages=messages,\n",
        "    temperature=0.7,\n",
        "    max_tokens=500,\n",
        ")\n",
        "\n",
        "response = model.chat(payload)\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response.choices[0].message.content))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252c7892-8d50-49c3-991c-d161d2daba9e",
      "metadata": {
        "id": "252c7892-8d50-49c3-991c-d161d2daba9e"
      },
      "source": [
        "------------------------------------------------\n",
        "Для расширения контекста можно дополнять блок `messages` аналогично списку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c85f45f6-dafa-4299-bfe4-dbc2f75933b4",
      "metadata": {
        "scrolled": true,
        "id": "c85f45f6-dafa-4299-bfe4-dbc2f75933b4",
        "outputId": "5a833594-cd72-4f82-aa68-3a0388f68ae5"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<blockquote>\n",
              "\n",
              "**Prompt Engineering (инженерия подсказок)** — это процесс разработки и оптимизации входных данных (подсказок) для моделей машинного обучения с целью получения наилучших результатов от них.\n",
              "\n",
              "### Роли участников процесса:\n",
              "- **Разработчик модели**: создает и обучает саму модель машинного обучения.\n",
              "- **Инженер по подсказкам (Prompt Engineer)**: разрабатывает и тестирует различные варианты подсказок, подбирая оптимальный запрос для конкретной задачи.\n",
              "- **Пользователь**: получает итоговый результат"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "payload.messages.append(Messages(role=MessagesRole.USER, content=response.choices[0].message.content))\n",
        "payload.messages.append(Messages(role=MessagesRole.USER, content=\"Уточни контент определением ролей\"))\n",
        "\n",
        "response = model.chat(payload)\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response.choices[0].message.content))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beed0df6-67b0-494e-a363-982198a1335e",
      "metadata": {
        "id": "beed0df6-67b0-494e-a363-982198a1335e"
      },
      "source": [
        "### Упражнения\n",
        "1. Разработать системный промпт, который на запрос пользователя возвращет суммаризацию запроса и ответ на заопрос.\n",
        "2. Разработать помпт, который на запрос пользователя всегда будет отчечать в стиле выбранного писателя.\n",
        "3. Проверить влияние температуры и длины ответа на его качество.\n",
        "4. Разработать промпт который будет на выходе давать  формат `JSON`, например\n",
        "```json\n",
        "{\n",
        "  \"defenition\": \"Prompt Engineering (инженерия подсказок) — это процесс разработки и оптимизации входных данных (подсказок) для языковых моделей искусственного интеллекта, направленный на получение максимально полезных и точных результатов от модели.\",\n",
        "  \"properties\": \"Четкость формулировки: запрос должен быть четко сформулированным и понятным модели. Контекстуальность: предоставление достаточного контекста помогает модели лучше понять задачу.Гибкость и итерационность: часто требуется несколько попыток\",\n",
        "  \"roles\": \"Пользователь: человек, задающий вопрос или требующий выполнения задачи, получающий результат работы модели. Модель: система искусственного интеллекта, принимающая запросы (подсказки), выполняющая обработку информации.\"\n",
        "}```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "802d2dcd-f784-4125-a38b-f3a5322f852d",
      "metadata": {
        "id": "802d2dcd-f784-4125-a38b-f3a5322f852d"
      },
      "outputs": [],
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.SYSTEM,\n",
        "            content=(\n",
        "                \"\"\"\n",
        "                Ты полезный ассистент для тестирования ГигаЧата. Твоя задача отвечать студенту на учебные вопросы\n",
        "                Отвечай кратко и ёмко!\n",
        "                ## Шаблон ответа:\n",
        "                Запрос: {суммаризация запроса пользователя}.\n",
        "                Ответ: {ответ на запрос со списками, таблицами}.\n",
        "                Роли: {роли по информации запроса}.\n",
        "                ## Формат\n",
        "                Markdown\n",
        "                \"\"\"\n",
        "            )\n",
        "        ),\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.SYSTEM,\n",
        "            content=(\n",
        "                \"\"\"\n",
        "                Ты полезный ассистент для тестирования ГигаЧата. Твоя задача отвечать студенту на учебные вопросы\n",
        "                Отвечай кратко и ёмко!\n",
        "                ## Шаблон ответа:\n",
        "                {\n",
        "                  \"defenition\": \"\",\n",
        "                  \"properties\": \"\",\n",
        "                  \"roles\": \"\"\n",
        "                }\n",
        "                ## Формат\n",
        "                JSON\n",
        "                \"\"\"\n",
        "            )\n",
        "        ),\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        ),\n",
        "    ]"
      ],
      "metadata": {
        "id": "twj1-1ypgMKn"
      },
      "id": "twj1-1ypgMKn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ded0d7-c55d-43b3-82f8-8f6511106e24",
      "metadata": {
        "id": "f4ded0d7-c55d-43b3-82f8-8f6511106e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "e0066a25-f29a-481c-c853-899067080306"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\n{\n  \"definition\": \"Prompt Engineering — это процесс создания эффективных подсказок (prompt) для оптимизации работы моделей машинного обучения, особенно языковых моделей.\",\n  \"properties\": [\n    \"Точность формулировки запроса\",\n    \"Использование специальных маркеров и форматов данных\",\n    \"Тестирование различных вариантов подсказки\"\n  ],\n  \"roles\": \"Помогает достичь более точных и релевантных ответов от модели.\"\n}"
          },
          "metadata": {}
        }
      ],
      "source": [
        "payload = Chat(\n",
        "    messages=messages,\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        ")\n",
        "\n",
        "response = model.chat(payload)\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8050f0b9-75b9-4ad2-83ad-c612346f4b94",
      "metadata": {
        "id": "8050f0b9-75b9-4ad2-83ad-c612346f4b94"
      },
      "source": [
        "# Функции и Актуализация запросов к модели\n",
        "\n",
        "Языковые модели, включая `GigaChat`, обучены на данных, зафиксированных до определённой даты. Они не знают, что происходит «здесь и сейчас».\n",
        "Но если дать модели возможность вызвать функцию, которая получит свежие данные (например, через поисковик), — она сможет дать актуальный и точный ответ.\n",
        "\n",
        "[Механизм вызова функций](https://habr.com/ru/articles/806627/) называется `Function Calling` — механизм, при котором модель:\n",
        "* Решает, нужно ли вызвать функцию.\n",
        "* Формирует структурированный запрос к функции (с аргументами).\n",
        "* Система выполняет функцию.\n",
        "* Результат возвращается модели, и она формулирует финальный ответ.\n",
        "\n",
        "\n",
        "__Другими словами__ при использовании `Function Calling` в запрос передаётся не только история сообщений, но и список доступных функций.\n",
        "Модель анализирует контекст и решает:\n",
        "Ответить сразу, или вернуть специальное сообщение с `function_call`. Во втором случае будет необходимо вызвать функцию и повторно запросить модель.\n",
        "\n",
        "> Отметим, что не все модели подддерживают `Function Calling`.\n",
        "\n",
        "Создадим функцию  `search_ddg`, которая использует библиотеку `ddgs` для получения актуальных результатов поиска.\n",
        "Где `ddgs` — это библиотека для поиска в `DuckDuckGo`. `DuckDuckGo` выбран, потому что он не требует API-ключа."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef4894e5-aebe-40dc-bda2-f6c99c839a68",
      "metadata": {
        "id": "ef4894e5-aebe-40dc-bda2-f6c99c839a68"
      },
      "outputs": [],
      "source": [
        "def search_ddg(search_query):\n",
        "    \"\"\"Поиск в DuckDuckGo.\n",
        "        Полезен, когда нужно ответить на вопросы о текущих событиях.\n",
        "        Входными данными должен быть поисковый запрос.\"\"\"\n",
        "    return DDGS().text(search_query, max_results=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2d015e-bf0f-4239-9aa0-b2955430b534",
      "metadata": {
        "id": "0a2d015e-bf0f-4239-9aa0-b2955430b534",
        "outputId": "ff600e7f-358a-455d-e7c2-78f7008ec12d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'GISMETEO: Погода в Екатеринбурге сегодня, прогноз погоды ...', 'href': 'https://www.gismeteo.ru/weather-yekaterinburg-4517/', 'body': 'Погода в Екатеринбурге на сегодня , подробный прогноз погоды на сегодня для населенного пункта Екатеринбург , городской округ Екатеринбург , Свердловская область, Россия.'}\n"
          ]
        }
      ],
      "source": [
        "results = search_ddg(MESSAGE)\n",
        "print(results[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ce27cab-0ece-4e17-b87f-950149bc0275",
      "metadata": {
        "id": "8ce27cab-0ece-4e17-b87f-950149bc0275"
      },
      "source": [
        "-----------------------------------------------------------------------------\n",
        "\n",
        "Создадим объект `search` типа `Function` - для задания нашей функции `search_ddg` в формате, понятном модели:\n",
        "\n",
        "* `name` — уникальное имя, по которому модель будет её вызывать.\n",
        "* `description` — объяснение, когда и зачем использовать эту функцию.\n",
        "* `parameters` — схема входных данных (в стиле `JSON Schema`):\n",
        "\n",
        "\n",
        "На входе функции ожидается объект с полем `query` типа `string`. Поле `query` обязательно (`required`).\n",
        "Подход к описанию аналогичен «документации `API`», которую модель «читает» перед решением вызывать функцию или нет."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8759fdbc-0e1d-4869-97d6-292bf897c9a3",
      "metadata": {
        "id": "8759fdbc-0e1d-4869-97d6-292bf897c9a3"
      },
      "outputs": [],
      "source": [
        "search_func = Function(\n",
        "    name=\"duckduckgo_search\",\n",
        "    description=\"Поиск в DuckDuckGo для получения актуальной информации.\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\"query\": {\"type\": \"string\"}},\n",
        "        required=[\"query\"],\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9535ed0-5f12-4e3b-b145-89356a740eb7",
      "metadata": {
        "id": "f9535ed0-5f12-4e3b-b145-89356a740eb7"
      },
      "source": [
        "Для того чтобы модель могла вызывать функцию подадаим `search_func` в качестве значения аргумента `functions` объекта `Chat`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0da5d2fd-9e50-4286-8458-3d04fc662593",
      "metadata": {
        "id": "0da5d2fd-9e50-4286-8458-3d04fc662593",
        "outputId": "bb9208aa-50d0-484c-8b72-a4c667a26eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "role='assistant' content='' function_call=FunctionCall(name='duckduckgo_search', arguments={'query': 'prompt engineering определение и особенности'}) name=None attachments=None data_for_context=None functions_state_id='019ad592-1ac7-7c63-b0a1-f23e9c8cf492' reasoning_content=None id_=None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'function_call'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "messages = [\n",
        "        Messages(role=MessagesRole.USER, content=MESSAGE)\n",
        "    ]\n",
        "chat = Chat(messages=messages, functions=[search_func])\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "print(message)\n",
        "resp.finish_reason"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f0f8f57-5e6e-4228-a51f-f03d7a6e8bfa",
      "metadata": {
        "id": "8f0f8f57-5e6e-4228-a51f-f03d7a6e8bfa"
      },
      "source": [
        "В следующем коде проверяем, необходим  ли модели вызов функции. Если необходим, то\n",
        "* формируем запрос `query`\n",
        "* получаем результат при помощи `search_ddg`\n",
        "* дополняем сообщение для модели результатом запроса\n",
        "* формируем окончательный ответ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d749f3-6904-43cf-a895-440fd1250010",
      "metadata": {
        "id": "b4d749f3-6904-43cf-a895-440fd1250010",
        "outputId": "0d9c70fd-fb05-486c-e98b-e3120978fd91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\n**Prompt engineering** — это процесс структурирования или составления запроса таким образом, чтобы улучшить качество выходного результата от модели искусственного интеллекта (ИИ). \n\n### Особенности prompt engineering:\n\n1. **Четкость формулировки:** Важно создавать ясные и конкретные инструкции, чтобы направлять модель к нужному результату.\n   \n2. **Контекстуальность:** Добавление релевантной информации помогает модели лучше понимать контекст и формировать более точные ответы.\n\n3. **Итеративность:** Процесс часто включает многократное тестирование и уточнение запроса, чтобы достичь наилучшего возможного результата."
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Если модель хочет вызвать функцию\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func_name = message.function_call.name\n",
        "    query = message.function_call.arguments[\"query\"]\n",
        "\n",
        "    # Выполняем функцию\n",
        "    result = search_ddg(query)\n",
        "\n",
        "    # Шаг 2: отправляем результат обратно модели\n",
        "    messages.extend([\n",
        "        message,  # сообщение с function_call\n",
        "        Messages(role=MessagesRole.FUNCTION, content=json.dumps({\"result\": result}, ensure_ascii=False))\n",
        "    ])\n",
        "    final_resp = model.chat(Chat(messages=messages)).choices[0]\n",
        "    response = final_resp.message.content\n",
        "else:\n",
        "    # Модель ответила сразу\n",
        "    print('МОДЕЛЬ ОТВЕТИЛА СРАЗУ')\n",
        "    response = message.content\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "330c2c47-3f53-46e4-90f0-1e805f8b4213",
      "metadata": {
        "id": "330c2c47-3f53-46e4-90f0-1e805f8b4213"
      },
      "source": [
        "### Упражения\n",
        "1. Измените поле `desription` описания функции, например на\n",
        "    * \"Используй ТОЛЬКО для вопросов о погоде.\"\n",
        "    * \"Никогда не используй этот поиск.\"\n",
        "    * \"Это функция для поиска рецептов блюд.\"\n",
        "Проверьте как это скажется на результатах.\n",
        "2. Измените значение `max_results` в диапазоне 1 - 10, провеврьте как это скажется на качестве ответа\n",
        "3. Добавьте к примеру системный промпт, например \"Ты — помощник, который ВСЕГДА ищет информацию в интернете, даже если знаешь ответ.\"\n",
        "4. Добавьте функцию текущей даты к списку функций запроса.\n",
        "```python\n",
        "   def get_current_date():\n",
        "        \"\"\"Возвращает текущую дату в формате ГГГГ-ММ-ДД.\"\"\"\n",
        "        from datetime import datetime\n",
        "        return datetime.now().strftime(\"%Y-%m-%d\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_current_date():\n",
        "  from datetime import datetime\n",
        "  now = datetime.now()\n",
        "  today = datetime(year=now.year, month=now.month+1, day=5)\n",
        "  return today.strftime(\"%Y-%m-%d\")"
      ],
      "metadata": {
        "id": "a8VMnnDun0CY"
      },
      "id": "a8VMnnDun0CY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_current_date())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__jXjFNsn-GB",
        "outputId": "2f73c9f3-c252-40b1-9ade-f99037b9d850"
      },
      "id": "__jXjFNsn-GB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_func = Function(\n",
        "    name=\"get_current_date\",\n",
        "    description=\"Узнать дату сегодня (сегодняшний день, сегодняшнее число)\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={},\n",
        "        required=[],\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "RoThkfp0oAnX"
      },
      "id": "RoThkfp0oAnX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_func = Function(\n",
        "    name=\"duckduckgo_search\",\n",
        "    description=\"Поиск в DuckDuckGo для получения актуальной информации. Используй ТОЛЬКО для погоды и даты\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\"query\": {\"type\": \"string\"}},\n",
        "        required=[\"query\"],\n",
        "    ),\n",
        "    name=\"get_current_date\",\n",
        "    description=\"Узнать дату сегодня (сегодняшний день, сегодняшнее число)\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={},\n",
        "        required=[],\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "W6jgnXjYmJ-7",
        "outputId": "5b3f3aa4-90d5-44d9-a3f9-dcf93a95896f"
      },
      "id": "W6jgnXjYmJ-7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "keyword argument repeated: name (ipython-input-4086365309.py, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4086365309.py\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    name=\"get_current_date\",\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated: name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8350c04-5208-4cf8-95d7-ecd64e3db3b3",
      "metadata": {
        "id": "e8350c04-5208-4cf8-95d7-ecd64e3db3b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df1322d8-bd51-4143-da51-7319e44b60b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "role='assistant' content='' function_call=FunctionCall(name='get_current_date', arguments={}) name=None attachments=None data_for_context=None functions_state_id='019ad5a6-f225-7be9-b2d1-e7396283682b' reasoning_content=None id_=None\n"
          ]
        }
      ],
      "source": [
        "MESSAGE = \"Какое сегодня число?\"\n",
        "\n",
        "messages = [\n",
        "        Messages(role=MessagesRole.USER, content=MESSAGE)\n",
        "    ]\n",
        "\n",
        "chat = Chat(messages=messages, functions=[search_func], max_tokens=100)\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "print(message)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Если модель хочет вызвать функцию\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func_name = message.function_call.name\n",
        "\n",
        "    # Выполняем функцию\n",
        "    if func_name == \"duckduckgo_search\":\n",
        "      query = message.function_call.arguments[\"query\"]\n",
        "      result = search_ddg(query)\n",
        "    elif func_name == \"get_current_date\":\n",
        "      result = get_current_date()\n",
        "\n",
        "    # Шаг 2: отправляем результат обратно модели\n",
        "    messages.extend([\n",
        "        message,  # сообщение с function_call\n",
        "        Messages(role=MessagesRole.FUNCTION, content=json.dumps({\"result\": result}, ensure_ascii=False))\n",
        "    ])\n",
        "    final_resp = model.chat(Chat(messages=messages)).choices[0]\n",
        "    response = final_resp.message.content\n",
        "else:\n",
        "    # Модель ответила сразу\n",
        "    print('МОДЕЛЬ ОТВЕТИЛА СРАЗУ')\n",
        "    response = message.content\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "T4j4F5JMoVFF",
        "outputId": "dc62912e-5f52-4d0e-be68-38c7d8061ac2"
      },
      "id": "T4j4F5JMoVFF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\nСегодня 5 декабря 2025 года."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4778da43-9f46-49e8-8c6b-dcbeab29fa6a",
      "metadata": {
        "id": "4778da43-9f46-49e8-8c6b-dcbeab29fa6a"
      },
      "source": [
        "## Упражения 2\n",
        "\n",
        "Создадим свой калькулятор при помощи функций `GigaChat`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dda6449-cdb8-422e-923d-329572489166",
      "metadata": {
        "id": "6dda6449-cdb8-422e-923d-329572489166"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def safe_calculate(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Выполняет математическое выражение.\n",
        "    Поддерживает: +, -, *, /, **, скобки, числа с точкой.\n",
        "    Безопасен: разрешает ТОЛЬКО математические символы.\n",
        "    \"\"\"\n",
        "    # Разрешённые символы: цифры, операторы, скобки, точка, пробелы\n",
        "    if not re.fullmatch(r'[\\d+\\-*/().\\s]+', expression):\n",
        "        return \"Ошибка: выражение содержит недопустимые символы.\"\n",
        "\n",
        "    try:\n",
        "        # Ограничиваем сложность (например, не даём выполнить 9**9**9)\n",
        "        if '^' in expression or len(expression) > 50:\n",
        "            return \"Ошибка: выражение слишком сложное или длинное.\"\n",
        "\n",
        "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
        "        return str(result)\n",
        "    except Exception as e:\n",
        "        return f\"Ошибка вычисления: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4387a9e3-15cc-416e-bd0d-87107b8f7178",
      "metadata": {
        "id": "4387a9e3-15cc-416e-bd0d-87107b8f7178",
        "outputId": "2c2d6d8c-73f6-4590-e202-a58fd68c7160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'243'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "safe_calculate('3*(4+5)**2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ccfa93f-9a97-41fb-ae91-7acca80eadb6",
      "metadata": {
        "id": "7ccfa93f-9a97-41fb-ae91-7acca80eadb6"
      },
      "outputs": [],
      "source": [
        "calculate_func = Function(\n",
        "    name=\"calculate\",\n",
        "    description=\"Выполняет математические вычисления. Передавай ТОЛЬКО выражение в виде строки, например: '2 + 3 * 4'.\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\n",
        "            \"expression\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Математическое выражение (только цифры, +, -, *, /, **, скобки)\"\n",
        "            }\n",
        "        },\n",
        "        required=[\"expression\"],\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01bbf602-9bf9-421e-aeab-cb882584e722",
      "metadata": {
        "id": "01bbf602-9bf9-421e-aeab-cb882584e722"
      },
      "outputs": [],
      "source": [
        "message = 'Сколько будет 3*(4+5)**2'\n",
        "\n",
        "messages = [\n",
        "    Messages(role=MessagesRole.USER, content=message)\n",
        "]\n",
        "\n",
        "chat = Chat(messages=messages, functions=[calculate_func])\n",
        "\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func = message.function_call\n",
        "    if func.name == \"calculate\":\n",
        "        expr = func.arguments.get(\"expression\", \"\")\n",
        "        result = safe_calculate(expr)\n",
        "        # Возвращаем результат модели\n",
        "        messages.extend([\n",
        "            message,\n",
        "            Messages(role=MessagesRole.FUNCTION, content=result)\n",
        "        ])\n",
        "        # Получаем финальный ответ\n",
        "        final = model.chat(Chat(messages=messages)).choices[0]\n",
        "        response =  final.message.content\n",
        "else:\n",
        "    # Модель ответила без вычислений (например, объяснила задачу)\n",
        "    response = message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f920ef5-e42d-4419-957e-66ce8b60cd75",
      "metadata": {
        "id": "3f920ef5-e42d-4419-957e-66ce8b60cd75",
        "outputId": "13adbbb8-fa76-4b5b-bd63-c0a7c01f0123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\nРешим выражение пошагово:\n\n1. Сначала выполним действие в скобках:  \n$4 + 5 = 9$\n\n2. Возведём полученное число в квадрат:  \n$9^2 = 81$\n\n3. Теперь умножим результат на 3:  \n$3 \\cdot 81 = 243$\n\n**Итоговый ответ:** $\\mathbf{243}$"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(\"<blockquote>\\n\\n\"+response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b42ecb18-022c-4307-8c63-a431b8213837",
      "metadata": {
        "id": "b42ecb18-022c-4307-8c63-a431b8213837"
      },
      "source": [
        "__Упражения__\n",
        "1. Сделайте проверку на sin/cos в функции калькулятора\n",
        "   \n",
        "2. Расширьте функционал калькулятора"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_func = Function(\n",
        "    name=\"calculate\",\n",
        "    description=\"Выполняет математические вычисления. Передавай ТОЛЬКО выражение в виде строки, например: '2 + 3 * 4'.\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\n",
        "            \"expression\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Математическое выражение (только цифры, +, -, *, /, **, скобки)\"\n",
        "            }\n",
        "        },\n",
        "        required=[\"expression\"],\n",
        "    )\n",
        ")\n",
        "\n",
        "sin_func = Function(\n",
        "    name=\"sin\",\n",
        "    description=\"Находит синус выражения. ВАЖНО, сначала высчитай синусы, потом замени синусы на реальные значения и передай аргумент функции калькулятора\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\n",
        "            \"value\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Значение угла в радианах\"\n",
        "            }\n",
        "        },\n",
        "        required=[\"value\"],\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "kZza6pPdsU2s"
      },
      "id": "kZza6pPdsU2s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = 'Сколько будет 55*243?'\n",
        "\n",
        "messages = [\n",
        "    Messages(role=MessagesRole.USER, content=message)\n",
        "]\n",
        "\n",
        "chat = Chat(messages=messages, functions=[calculate_func, sin_func], max_tokens=100)\n",
        "\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func = message.function_call\n",
        "    if func.name == \"calculate\":\n",
        "        print(\"Калькулирую!\")\n",
        "        expr = func.arguments.get(\"expression\", \"\")\n",
        "        result = safe_calculate(expr)\n",
        "    elif func.name == \"sin\":\n",
        "        value = func.arguments.get(\"value\", \"\")\n",
        "        print(\"Расчёты!\")\n",
        "        result = eval(f\"sin({value})\")\n",
        "    # Возвращаем результат модели\n",
        "    messages.extend([\n",
        "        message,\n",
        "        Messages(role=MessagesRole.FUNCTION, content=result)\n",
        "    ])\n",
        "    # Получаем финальный ответ\n",
        "    final = model.chat(Chat(messages=messages)).choices[0]\n",
        "    response =  final.message.content\n",
        "else:\n",
        "    # Модель ответила без вычислений (например, объяснила задачу)\n",
        "    response = message.content"
      ],
      "metadata": {
        "id": "GICchSqBs-Qp",
        "outputId": "0ace3a22-d801-41ac-87ce-e13cb092799b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GICchSqBs-Qp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Калькулирую!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "PQJ0J2k9vD3N",
        "outputId": "47c85308-7c83-45e7-f205-439af5b0e047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PQJ0J2k9vD3N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Произведение чисел 55 и 243 равно $ \\fbox{13365} $.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d09d2294-0782-460f-bfdc-dc3cd52c125f",
      "metadata": {
        "id": "d09d2294-0782-460f-bfdc-dc3cd52c125f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c9f966b-3596-4846-d280-e0b0d5636609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.0\n"
          ]
        }
      ],
      "source": [
        "from math import sin, cos, pi\n",
        "print(sin(3*pi/2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de6e24ea-1c04-4a74-bf83-9d69a5adf892",
      "metadata": {
        "id": "de6e24ea-1c04-4a74-bf83-9d69a5adf892"
      },
      "source": [
        "# <span style=\"color:red\">Опционально.</span> О более продвинутом пути к LLM-приложениям"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P.S. По какой-то причине у меня не работает адекватно подгрузка GigaChain"
      ],
      "metadata": {
        "id": "ybZ8eEXzadsO"
      },
      "id": "ybZ8eEXzadsO"
    },
    {
      "cell_type": "markdown",
      "id": "28706415-a7d5-4db9-9ab6-7b18c45ae1f4",
      "metadata": {
        "id": "28706415-a7d5-4db9-9ab6-7b18c45ae1f4"
      },
      "source": [
        "Простой вызов языковой модели — как в примерах выше - подходит для однократных запросов. Но в реальных задачах ИИ-приложения редко ограничиваются одним вопросом. Чаще всего нам нужно:\n",
        "* вести диалог с памятью,\n",
        "* вызывать внешние инструменты (`tools`), например поиск, калькулятор, базы данных,\n",
        "* строить цепочки (`chains`) и комбинировать несколько шагов обработки информации (анализ → поиск → генерация),\n",
        "* управлять контекстом, форматом вывода и безопасностью.\n",
        "Для этого созданы спициальные библиотеки для работы с `LLM`, в том числе `LangChain` - фреймворк, который превращает LLM в ИИ-агента.\n",
        "`LangChain] берёт на себя всю типичную инфраструктуру: управление сообщениями, обработку вызовов функций, повторные запросы, форматирование  и позволяет вам сосредоточиться на логике приложения, а не на ручной сборке JSON-запросов.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2afb7c80-2fed-4c1f-88a4-23a167e293c9",
      "metadata": {
        "id": "2afb7c80-2fed-4c1f-88a4-23a167e293c9"
      },
      "source": [
        "[Гигачейн]()(`GigaChain`) - [это переделанная под работу с российскими моделями библиотека `Langchain`](https://github.com/trashchenkov/gigachat_tutorials/blob/main/%D0%B3%D0%B8%D0%B3%D0%B0%D1%87%D0%B5%D0%B9%D0%BD.ipynb). Исходная библиотека `Langchain` позволяет создавать сложные цепочки по обработке данных, поступающих из разных источников, и встраивать в эту обработку большие языковые модели.\n",
        "\n",
        "Функционал `Langchain` достаточно широкий и постоянно пополняется. Попробуем использовать `langchain_gigachat` (`gigachain`) для того чтобы более компактно работать с моделями"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_gigachat"
      ],
      "metadata": {
        "id": "q36DqYcbxDZA",
        "outputId": "3987f900-7184-46f2-cdb8-9f4bde18c7c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "id": "q36DqYcbxDZA",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_gigachat in /usr/local/lib/python3.12/dist-packages (0.3.12)\n",
            "Requirement already satisfied: gigachat<0.2.0,>=0.1.41.post1 in /usr/local/lib/python3.12/dist-packages (from langchain_gigachat) (0.1.43)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3 in /usr/local/lib/python3.12/dist-packages (from langchain_gigachat) (0.3.80)\n",
            "Requirement already satisfied: types-requests<3.0,>=2.32 in /usr/local/lib/python3.12/dist-packages (from langchain_gigachat) (2.32.4.20250913)\n",
            "Requirement already satisfied: httpx<1 in /usr/local/lib/python3.12/dist-packages (from gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1 in /usr/local/lib/python3.12/dist-packages (from gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (2.12.3)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (0.4.56)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (25.0)\n",
            "Requirement already satisfied: urllib3>=2 in /usr/local/lib/python3.12/dist-packages (from types-requests<3.0,>=2.32->langchain_gigachat) (2.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<0.4,>=0.3->langchain_gigachat) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (2.32.4)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (0.12.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (3.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "j9819xjLxfRu",
        "outputId": "9c24afdc-28fd-4d2c-e9b7-51af5f8baa2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        }
      },
      "id": "j9819xjLxfRu",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
            "Collecting langchain-core<2.0.0,>=1.1.2 (from langchain)\n",
            "  Using cached langchain_core-1.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.4.56)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (2.5.0)\n",
            "Using cached langchain_core-1.2.2-py3-none-any.whl (476 kB)\n",
            "Installing collected packages: langchain-core\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.80\n",
            "    Uninstalling langchain-core-0.3.80:\n",
            "      Successfully uninstalled langchain-core-0.3.80\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-gigachat 0.3.12 requires langchain-core<0.4,>=0.3, but you have langchain-core 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.2.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain_core"
                ]
              },
              "id": "88ac4c3b4c0748ff847ad4d239c0b313"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "eWE8v4I3iBH4",
        "outputId": "73e9cd19-9032-4bd1-bb18-82983bf2d1b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eWE8v4I3iBH4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.2)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.4.56)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community"
      ],
      "metadata": {
        "id": "cBbVejG6jN3V",
        "outputId": "6ec1a424-cfb1-4628-a6eb-d463d3eed652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "cBbVejG6jN3V",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.2)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.56)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-1.2.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.8/102.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain-community, langchain\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 1.1.3\n",
            "    Uninstalling langchain-1.1.3:\n",
            "      Successfully uninstalled langchain-1.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-1.2.0 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-text-splitters-1.1.0 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain",
                  "requests"
                ]
              },
              "id": "c51a52489a104010ad4a0ee69ce275c3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "57a311e9-7a90-4aef-801e-010ec53b3e89",
      "metadata": {
        "id": "57a311e9-7a90-4aef-801e-010ec53b3e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "19278916-bd24-45dd-fc44-c794835ae3a2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'AgentExecutor' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1196157024.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_gigachat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGigaChat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_tool_calling_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMessagesPlaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSystemMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHumanMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAIMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFunctionMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'AgentExecutor' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from langchain_gigachat import GigaChat\n",
        "from langchain_core.tools import tool\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, FunctionMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "219a10ac-9507-43eb-90f8-9143b709ded6",
      "metadata": {
        "id": "219a10ac-9507-43eb-90f8-9143b709ded6"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "62cc963b-0bd4-4683-b651-16903e4bdb0f",
      "metadata": {
        "id": "62cc963b-0bd4-4683-b651-16903e4bdb0f",
        "outputId": "8ef7a370-a560-48ad-f3ce-2cf50bf6757c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'auth' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1646830656.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m llm = GigaChat(\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GigaChat-Pro\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mverify_ssl_certs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstreaming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'auth' is not defined"
          ]
        }
      ],
      "source": [
        "# Инициализация модели\n",
        "llm = GigaChat(\n",
        "    model=\"GigaChat-Pro\",\n",
        "    credentials=auth,\n",
        "    verify_ssl_certs=False,\n",
        "    streaming=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1930148-9153-4ad6-8acb-89f101e98a13",
      "metadata": {
        "id": "a1930148-9153-4ad6-8acb-89f101e98a13"
      },
      "source": [
        "В `Langchain` есть классы `HumanMessage`, `SystemMessage` и `AssistantMessage` для удобного представления словарей сообщений.\n",
        "\n",
        "Например вмето записи сообщания в стиле:\n",
        "```json\n",
        "{'role': 'system',\n",
        "'content': 'Отвечай как бывалый пират. Пусть тебя зовут Генри Морган.'\n",
        "}\n",
        "```\n",
        "теперь можем записать:\n",
        "```python\n",
        "SystemMessage(content='Отвечай как бывалый пират. Пусть тебя зовут Генри Морган.')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ff59ca8-ad87-4fb2-b51e-6a90cb2dbabc",
      "metadata": {
        "id": "9ff59ca8-ad87-4fb2-b51e-6a90cb2dbabc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "812ee915-ffd2-405f-acda-fedcf7fb476d",
      "metadata": {
        "id": "812ee915-ffd2-405f-acda-fedcf7fb476d",
        "outputId": "0e110ab5-f1cf-4509-a1e9-371c70465299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SystemMessage' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3412405460.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSystemMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Отвечай как инженр-датасаинтист с 20 летним опытом. Используй Markdown разметку ответа. Ответ не должен быть длинее 10 строк'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Какие приемущества может дать langchain в работе с GigaChat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SystemMessage' is not defined"
          ]
        }
      ],
      "source": [
        "msg = [SystemMessage(content='Отвечай как инженр-датасаинтист с 20 летним опытом. Используй Markdown разметку ответа. Ответ не должен быть длинее 10 строк')]\n",
        "\n",
        "question = \"Какие приемущества может дать langchain в работе с GigaChat\"\n",
        "\n",
        "msg.append(HumanMessage(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396a1ef5-a52c-459e-9ec8-0b1f1e6ca97d",
      "metadata": {
        "scrolled": true,
        "id": "396a1ef5-a52c-459e-9ec8-0b1f1e6ca97d",
        "outputId": "53005e16-8f83-4b4f-a5b0-b733f7fa8277"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<blockquote>\n",
              "\n",
              "**Преимущества использования LangChain для работы с GigaChat:**\n",
              "\n",
              "- **Интеграция и управление знаниями:** позволяет эффективно использовать и обновлять корпоративные данные.\n",
              "- **Повышение точности ответов:** доступ к актуальным данным улучшает качество генерируемых решений.\n",
              "- **Автоматизация процессов:** упрощает создание автоматизированных рабочих потоков, снижая трудозатраты.\n",
              "- **Безопасность данных:** обеспечивает локальное хранение конфиденциальной информации без передачи третьим лицам.\n",
              "- **Ускорение разработки:** предоставляет готовые компоненты и шаблоны для быстрого прототипирования и вн"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = llm(msg).content[:600]\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+results))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e36f412e-86b4-46d9-8283-db22049ef71a",
      "metadata": {
        "id": "e36f412e-86b4-46d9-8283-db22049ef71a"
      },
      "source": [
        "При помощи класса `AIMessage` `LangChain` позволяет сохранить ответ на первое сообщение и использовать этот результат при вторичном запросе. В нашем случае попросим уточнить `GigaChat` примеры кода для нашего запроса.\n",
        "\n",
        "В примере будем использовать метод `invoke` - часть унифицированного `Runnable API (LangChain 0.1.0+)`.\n",
        "Прямой вызов - устаревший подход, может быть удален в будущем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b7d1357-6954-4d58-9b10-92b6d57314e5",
      "metadata": {
        "scrolled": true,
        "id": "9b7d1357-6954-4d58-9b10-92b6d57314e5",
        "outputId": "63ee8fed-8515-4fea-d117-5aae7fd5e4e6"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<blockquote>\n",
              "\n",
              "```python\n",
              "from langchain.llms import HuggingFaceHub\n",
              "from langchain.chains import LLMChain\n",
              "from langchain.prompts import PromptTemplate\n",
              "\n",
              "# Настройка GigaChat через Hugging Face Hub API\n",
              "llm = HuggingFaceHub(repo_id=\"gigachat\", huggingfacehub_api_token=\"YOUR_API_TOKEN\")\n",
              "\n",
              "# Создание шаблона запроса\n",
              "prompt_template = PromptTemplate(\n",
              "    input_variables=[\"question\"],\n",
              "    template=\"{question}\"\n",
              ")\n",
              "\n",
              "# Создание цепочки (chain)\n",
              "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
              "\n",
              "# Запуск цепочки с конкретным вопросом\n",
              "response = chain.run(\"Каковы преимущества использования контейнеризации?\")\n",
              "print(response)\n",
              "```\n",
              "\n",
              "**Пример демонстрирует:**  \n",
              "- Интеграцию GigaChat через Hugging Face Hub API;  \n",
              "- Использование простого цепочного подхода для обработки пользовательских запросов."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Получаем ответ\n",
        "response = llm.invoke(msg)  # Используем invoke вместо прямого вызова\n",
        "results = response.content[:600]\n",
        "\n",
        "# Сохраняем ответ в историю\n",
        "msg.append(AIMessage(content=results))\n",
        "\n",
        "# Пример продолжения диалога с историей\n",
        "follow_up_question = \"Можешь привести конкретный пример использования цепочки (chain) с GigaChat (langchain_gigachat)?\"\n",
        "msg.append(HumanMessage(content=follow_up_question))\n",
        "\n",
        "# Получаем ответ с учетом всей истории\n",
        "follow_up_response = llm.invoke(msg)\n",
        "msg.append(AIMessage(content=follow_up_response.content))\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+follow_up_response.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "502c9b23-24bc-4ca2-ab8f-0fa4b91c9fcf",
      "metadata": {
        "id": "502c9b23-24bc-4ca2-ab8f-0fa4b91c9fcf"
      },
      "source": [
        "Попробуем также в целях демонстрации возможностей `langchain` создать цепочку рассуджений. Для этого воспользуемся специальным классом `PromptTemplate`, который позволяет создавать шаблоны запросов аналогично f-функциям"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "662eef72-9eba-4ddf-b8fe-405355191356",
      "metadata": {
        "id": "662eef72-9eba-4ddf-b8fe-405355191356",
        "outputId": "a6b8d8f3-2161-4f96-86a1-963be7665a12"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**Задача:\n",
              "** В классе 30 учеников. 40% из них - девочки. Сколько мальчиков в классе?\n",
              "----------------------------"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Решение:\n",
              "\n",
              "** ### Шаг 1. Понимание условия задачи\n",
              "\n",
              "Дано:\n",
              "- Всего учеников в классе — 30 человек.\n",
              "- Девочки составляют $40\\%$ от общего числа учеников.\n",
              "\n",
              "Нужно найти:\n",
              "- Количество мальчиков в классе.\n",
              "\n",
              "---\n",
              "\n",
              "### Шаг 2. Логическая последовательность решения\n",
              "\n",
              "1. Найдём количество девочек (это будет $40\\%$ от всех учеников).\n",
              "2. Отнимем полученное число девочек от общего количества учеников, чтобы узнать количество мальчиков.\n",
              "\n",
              "---\n",
              "\n",
              "### Шаг 3. Вычисления по шагам\n",
              "\n",
              "#### Шаг 3.1. Нахождение количества девочек\n",
              "\n",
              "Общее количество учеников составляет $30$. Человек.\n",
              "\n",
              "Найдем $40\\%$ от $30$:\n",
              "\\[\n",
              "\\frac{40}{100} \\times 30 = 0.4 \\times 30 = 12\\ (\\text{девочек})\n",
              "\\]\n",
              "\n",
              "Таким образом, в классе $12$ девочек.\n",
              "\n",
              "#### Шаг 3.2. Нахождение количества мальчиков\n",
              "\n",
              "Из общего числа учеников вычитаем количество девочек:\n",
              "\\[\n",
              "30 - 12 = 18\\ (\\text{мальчиков})\n",
              "\\]\n",
              "\n",
              "Получили, что в классе $18$ мальчиков.\n",
              "\n",
              "---\n",
              "\n",
              "### Шаг 4. Проверка правильности\n",
              "\n",
              "Проверим корректность наших вычислений:\n",
              "\n",
              "- $40\\%$ от $30$ действительно равно $12$.\n",
              "- Если отнять $12$ девочек от $30$, останется ровно $18$ мальчиков.\n",
              "\n",
              "Вычисления верны.\n",
              "\n",
              "---\n",
              "\n",
              "### Ответ:\n",
              "\n",
              "В классе $18$ мальчиков."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "**Задача:\n",
              "** Книга стоит 500 рублей. После скидки цена снизилась на 20%. Сколько стоит книга после скидки?\n",
              "----------------------------"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Решение:\n",
              "\n",
              "** ### Шаг 1: Понимание условия задачи\n",
              "\n",
              "Дано:\n",
              "- Исходная стоимость книги — 500 рублей.\n",
              "- Размер скидки — 20%.\n",
              "\n",
              "Нужно найти:\n",
              "- Стоимость книги после применения скидки.\n",
              "\n",
              "---\n",
              "\n",
              "### Шаг 2: Логическая разбивка решения\n",
              "\n",
              "Для нахождения стоимости товара после скидки выполним следующие шаги:\n",
              "\n",
              "1. Найдём размер скидки (в рублях).\n",
              "2. Вычтем найденную скидку из исходной цены.\n",
              "\n",
              "---\n",
              "\n",
              "### Шаг 3: Вычисления\n",
              "\n",
              "#### 1. Нахождение размера скидки:\n",
              "Скидка составляет 20% от 500 рублей.\n",
              "\n",
              "$500 \\times \\frac{20}{100} = 500 \\times 0.2 = 100$ рублей.\n",
              "\n",
              "#### 2. Вычитание скидки из первоначальной цены:\n",
              "Новая цена будет равна исходной цене минус скидка:\n",
              "\n",
              "$500 - 100 = 400$ рублей.\n",
              "\n",
              "---\n",
              "\n",
              "### Шаг 4: Проверка правильности рассуждений\n",
              "\n",
              "Проверим, действительно ли получилась правильная скидка:\n",
              "- Если отнять 100 рублей от 500, получаем 400.\n",
              "- Это соответствует уменьшению цены на 20%, так как $\\frac{100}{500} \\times 100\\% = 20\\%$.\n",
              "\n",
              "Таким образом, рассуждения верны.\n",
              "\n",
              "---\n",
              "\n",
              "### Ответ:\n",
              "\n",
              "После скидки книга стоит **400 рублей**."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Создаем шаблон для Chain of Thought\n",
        "cot_template = \"\"\"\n",
        "Реши задачу шаг за шагом:\n",
        "\n",
        "Задача: {problem}\n",
        "\n",
        "Пожалуйста:\n",
        "1. Сначала пойми, что дано и что нужно найти\n",
        "2. Разбей решение на логические шаги\n",
        "3. Выполни вычисления для каждого шага\n",
        "4. Проверь правильность рассуждений\n",
        "5. Сформулируй окончательный ответ\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cot_prompt = PromptTemplate(\n",
        "    input_variables=[\"problem\"],\n",
        "    template=cot_template\n",
        ")\n",
        "\n",
        "# Создаем цепочку\n",
        "cot_chain = LLMChain(llm=llm, prompt=cot_prompt)\n",
        "\n",
        "# Используем\n",
        "problems = [\n",
        "    \"В классе 30 учеников. 40% из них - девочки. Сколько мальчиков в классе?\",\n",
        "    \"Книга стоит 500 рублей. После скидки цена снизилась на 20%. Сколько стоит книга после скидки?\",\n",
        "]\n",
        "\n",
        "for problem in problems:\n",
        "    result = cot_chain.run(problem=problem)\n",
        "    display(Markdown(f\"**Задача:\\n** {problem}\\n----------------------------\"))\n",
        "    display(Markdown(f\"**Решение:\\n\\n** {result}\"))\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dbd67a2-b43b-48f9-92fc-6606809084e8",
      "metadata": {
        "id": "9dbd67a2-b43b-48f9-92fc-6606809084e8"
      },
      "source": [
        "### Упражнение:\n",
        "\n",
        "Проверьте качество работы цепочки рассуждений для разных категорий вопросов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca45eef-48b9-46e2-be61-877e56d11b06",
      "metadata": {
        "id": "fca45eef-48b9-46e2-be61-877e56d11b06"
      },
      "outputs": [],
      "source": [
        "problems = [\n",
        "    \"В классе 30 учеников. 40% из них - девочки. Сколько мальчиков в классе?\",\n",
        "    \"Книга стоит 500 рублей. После скидки цена снизилась на 20%. Сколько стоит книга после скидки?\",\n",
        "]\n",
        "\n",
        "for problem in problems:\n",
        "    result = cot_chain.run(problem=problem)\n",
        "    display(Markdown(f\"**Задача:\\n** {problem}\\n----------------------------\"))\n",
        "    display(Markdown(f\"**Решение:\\n\\n** {result}\"))\n",
        "    print(\"---\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}