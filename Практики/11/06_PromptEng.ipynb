{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hopesofbuzzy/URFU_adii/blob/main/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B8/11/06_PromptEng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c23371a-3f67-4e0d-be8d-a69967daa3a4",
      "metadata": {
        "id": "5c23371a-3f67-4e0d-be8d-a69967daa3a4"
      },
      "source": [
        "# Работа с LLM GigaChat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gigachat\n",
        "!pip install ddgs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OpshkKS5W2L",
        "outputId": "1142f839-cba4-4716-ea12-92f90227fa72",
        "collapsed": true
      },
      "id": "3OpshkKS5W2L",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gigachat\n",
            "  Downloading gigachat-0.1.43-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: httpx<1 in /usr/local/lib/python3.12/dist-packages (from gigachat) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1 in /usr/local/lib/python3.12/dist-packages (from gigachat) (2.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1->gigachat) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (0.4.2)\n",
            "Downloading gigachat-0.1.43-py3-none-any.whl (69 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/69.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gigachat\n",
            "Successfully installed gigachat-0.1.43\n",
            "Collecting ddgs\n",
            "  Downloading ddgs-9.10.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from ddgs) (8.3.1)\n",
            "Collecting primp>=0.15.0 (from ddgs)\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=4.9.4 in /usr/local/lib/python3.12/dist-packages (from ddgs) (6.0.2)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
            "Collecting fake-useragent>=2.2.0 (from ddgs)\n",
            "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.2.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
            "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n",
            "Downloading ddgs-9.10.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: socksio, primp, fake-useragent, ddgs\n",
            "Successfully installed ddgs-9.10.0 fake-useragent-2.2.0 primp-0.15.0 socksio-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c75744f8-59dd-429a-94b7-442f4f06fc7e",
      "metadata": {
        "id": "c75744f8-59dd-429a-94b7-442f4f06fc7e"
      },
      "outputs": [],
      "source": [
        "from gigachat import GigaChat\n",
        "from gigachat.models import Chat, Function, FunctionParameters, Messages, MessagesRole\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "18c08934-96f1-44a3-8a35-ed7068751302",
      "metadata": {
        "id": "18c08934-96f1-44a3-8a35-ed7068751302"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from ddgs import DDGS\n",
        "\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client_id = userdata.get('SBER_ID')\n",
        "secret = userdata.get('SBER_SECRET')\n",
        "auth = userdata.get('SBER_AUTH')\n",
        "\n",
        "import base64\n",
        "credentials = f\"{client_id}:{secret}\"\n",
        "print(credentials)\n",
        "encoded_credentials = base64.b64encode(credentials.encode('utf-8')).decode('utf-8')\n",
        "\n",
        "\n",
        "encoded_credentials == auth"
      ],
      "metadata": {
        "id": "v3n9TJfP9xxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60e7c3c-0869-43fe-ebce-3a99d6065c24"
      },
      "id": "v3n9TJfP9xxJ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "019a6bdb-607f-745f-aafe-84a8fed0da0b:a2c04575-4ef1-480e-954e-afd1d3ac34ce\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9f74e41a-be15-4690-b439-4a0bf9ea1f63",
      "metadata": {
        "id": "9f74e41a-be15-4690-b439-4a0bf9ea1f63"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d6420c-d727-45aa-89a2-2379a852fd4f",
      "metadata": {
        "id": "17d6420c-d727-45aa-89a2-2379a852fd4f",
        "outputId": "8df99122-101b-4eb8-fd8e-a1853c101d72"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<blockquote>\n",
              "\n",
              "**Prompt Engineering (инжиниринг подсказок)** — это процесс тщательной разработки и настройки входной информации (подсказки), подаваемой модели машинного обучения (например, языковой модели), чтобы получить оптимальный результат выполнения поставленных задач.\n",
              "\n",
              "### Особенности Prompt Engineering:\n",
              "\n",
              "1. **Учет контекста**:  \n",
              "   Формулировка подсказки должна учитывать специфику поставленной задачи, включая тонкости формулировок, используемые термины и требуемый контекст.\n",
              "\n",
              "2. **Структурирование запроса**:  \n",
              "   Грамотная структура подсказки помогает модели эффективно понимать и обрабатывать запросы, снижая вероятность ошибок и улучшая качество результата.\n",
              "\n",
              "3. **Контроль выдачи**:  \n",
              "   Правильный выбор инструкций и шаблонов позволяет добиться нужной длины ответа, его точности и стилистики."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with GigaChat(credentials=token, verify_ssl_certs=False) as giga:\n",
        "    response = giga.chat(MESSAGE)\n",
        "    content = response.choices[0].message.content\n",
        "    display(Markdown(\"<blockquote>\\n\\n\"+content))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad6179e8-5d6b-4113-b673-d642dbfae6ea",
      "metadata": {
        "id": "ad6179e8-5d6b-4113-b673-d642dbfae6ea"
      },
      "source": [
        "______________________________________________________\n",
        "\n",
        "Перейдем к выбору моделей. Актуальный список моделей можно найти [тут](https://developers.sber.ru/docs/ru/gigachat/models). Модели могут отличатся качеством и разнообразием ответов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3206700-7371-493b-b20b-93c7a810d9f1",
      "metadata": {
        "scrolled": true,
        "id": "b3206700-7371-493b-b20b-93c7a810d9f1"
      },
      "outputs": [],
      "source": [
        "model = GigaChat(\n",
        "    model=\"GigaChat-2\",\n",
        "    credentials=auth,\n",
        "    verify_ssl_certs=False\n",
        ")\n",
        "\n",
        "\n",
        "# response = model.chat(MESSAGE)\n",
        "# content = response.choices[0].message.content\n",
        "# # print(content)\n",
        "# display(Markdown(\"<blockquote>\\n\\n\"+content))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e96d3c1-7b1e-41e5-98a6-8ed16772f6d2",
      "metadata": {
        "id": "0e96d3c1-7b1e-41e5-98a6-8ed16772f6d2"
      },
      "source": [
        "### Упражнения\n",
        "1. Предложите промпт, требующий знания информации на текущую дату, на дату несколько лет назад и на достаточно известное историческое событие, сравните и объясните результаты.\n",
        "2. Проверить качество результата запросов по категориям: математика, естественные науки, гуманитарные науки для разных моделей.\n",
        "3. Создайте небольшой диалог двух ИИ-персон"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebb17067-a6b8-4eef-b99e-32525d14c29b",
      "metadata": {
        "id": "ebb17067-a6b8-4eef-b99e-32525d14c29b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c126b203-a135-455f-b3e8-d4923ebb6fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Коронавирусная инфекция COVID-19 (вызываемая вирусом SARS-CoV-2) впервые была зафиксирована в конце декабря 2019 года в китайском городе Ухань провинции Хубэй. \n",
            "\n",
            "Первые случаи заражения связаны с рынком морепродуктов и живой птицы — предполагается, что источником инфекции могли стать животные. Вскоре после обнаружения заболевания оно быстро распространилось по всему миру, вызвав пандемию, объявленную Всемирной организацией здравоохранения 11 марта 2020 года.\n",
            "\n",
            "На сегодняшний день пандемия продолжает оставаться актуальной проблемой мировой медицины и общественного здравоохранения.\n"
          ]
        }
      ],
      "source": [
        "with GigaChat(credentials=auth, model=\"GigaChat-2\", verify_ssl_certs=False) as giga:\n",
        "  response = giga.chat(\"Когда случился Коронавирус\")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "DV2u3g6qB4_d"
      },
      "id": "DV2u3g6qB4_d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52e77a02-3307-4eaa-b9f1-9eedff40cea4",
      "metadata": {
        "id": "52e77a02-3307-4eaa-b9f1-9eedff40cea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "25a049f8-1ade-4972-ce08-67f52d782d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Объясни, что такое AI-agent?\n",
            "-----------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "AI-Agent (искусственный интеллектуальный агент) — это автономная система, способная действовать в окружающей среде самостоятельно, принимая решения и взаимодействуя с внешним миром согласно заданной цели или набору правил. Ключевые характеристики AI-агента включают:\n\n1. **Автономность**: агент действует независимо от человека, выполняя заранее запрограммированные или самообученные алгоритмы действий.\n   \n2. **Целевая ориентация**: агент имеет цель или набор целей, которые направляют его"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " поведение. Например, минимизировать затраты, максимизировать прибыль, достичь определённой точки пространства или получить доступ к ресурсам.\n\n3. **Интерактивность**: агент способен воспринимать окружение через сенсорную информацию (визуальные данные, звуковые сигналы, показания датчиков), анализировать её и реагировать соответствующим образом.\n\n4. **Адаптивность**: способность агента корректировать своё поведение на основе опыта взаимодействия с внешней средой, обучаясь новым стратегиям поведения и улучшая эффективность выполнения поставленных задач.\n\n5"
          },
          "metadata": {}
        }
      ],
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=\"Объясни, что такое AI-agent?\"\n",
        "        ),\n",
        "]\n",
        "\n",
        "payload = Chat(\n",
        "    messages=messages,\n",
        "    temperature=0.7,\n",
        "    max_tokens=100,\n",
        ")\n",
        "\n",
        "print(\"Объясни, что такое AI-agent?\")\n",
        "for role in [MessagesRole.ASSISTANT, MessagesRole.USER]:\n",
        "  with GigaChat(credentials=auth, model=\"GigaChat-2\", verify_ssl_certs=False) as giga:\n",
        "    response = giga.chat(payload)\n",
        "    payload.messages.append(Messages(role=role, content=response.choices[0].message.content))\n",
        "    print(\"-----------------\")\n",
        "    display(Markdown(response.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5be346c-4b50-498e-a6c2-397067ceed27",
      "metadata": {
        "id": "a5be346c-4b50-498e-a6c2-397067ceed27"
      },
      "source": [
        "\n",
        "# Роли и контекст запроса\n",
        "\n",
        "\n",
        "Более правиьно формулировать запросы (`payload`) к модели с использованием объекта типа `Chat`.\n",
        "`Chat` — это объект, описывающий весь чат-запрос к модели. Он содержит:\n",
        "* `messages` — список сообщений, представляющих историю диалога.\n",
        "* `temperature` — параметр, управляющий «творчеством» модели:\n",
        "    * Чем ближе температурак `0`, тем более детерминированный и предсказуемый ответ.\n",
        "    * Чем ближе температура к `1` (или выше), тем более случайный и разнообразный ответ.\n",
        "    * Например, значение `0.7` — баланс между креативностью и точностью.\n",
        "* `max_tokens` — ограничение на длину ответа модели (в токенах). Каждый токен приблизительно одно слово.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beed0df6-67b0-494e-a363-982198a1335e",
      "metadata": {
        "id": "beed0df6-67b0-494e-a363-982198a1335e"
      },
      "source": [
        "### Упражнения\n",
        "1. Разработать системный промпт, который на запрос пользователя возвращет суммаризацию запроса и ответ на заопрос.\n",
        "2. Разработать помпт, который на запрос пользователя всегда будет отчечать в стиле выбранного писателя.\n",
        "3. Проверить влияние температуры и длины ответа на его качество.\n",
        "4. Разработать промпт который будет на выходе давать  формат `JSON`, например\n",
        "```json\n",
        "{\n",
        "  \"defenition\": \"Prompt Engineering (инженерия подсказок) — это процесс разработки и оптимизации входных данных (подсказок) для языковых моделей искусственного интеллекта, направленный на получение максимально полезных и точных результатов от модели.\",\n",
        "  \"properties\": \"Четкость формулировки: запрос должен быть четко сформулированным и понятным модели. Контекстуальность: предоставление достаточного контекста помогает модели лучше понять задачу.Гибкость и итерационность: часто требуется несколько попыток\",\n",
        "  \"roles\": \"Пользователь: человек, задающий вопрос или требующий выполнения задачи, получающий результат работы модели. Модель: система искусственного интеллекта, принимающая запросы (подсказки), выполняющая обработку информации.\"\n",
        "}```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.SYSTEM,\n",
        "            content=(\n",
        "                \"\"\"\n",
        "                Ты полезный ассистент для тестирования ГигаЧата. Твоя задача отвечать в стиле выбранного писателя: Пушкин\n",
        "                ## Формат\n",
        "                Markdown\n",
        "                \"\"\"\n",
        "            )\n",
        "        ),\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        ),\n",
        "]"
      ],
      "metadata": {
        "id": "x56TQsQfP0B_"
      },
      "id": "x56TQsQfP0B_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "802d2dcd-f784-4125-a38b-f3a5322f852d",
      "metadata": {
        "id": "802d2dcd-f784-4125-a38b-f3a5322f852d"
      },
      "outputs": [],
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.SYSTEM,\n",
        "            content=(\n",
        "                \"\"\"\n",
        "                Ты полезный ассистент для тестирования ГигаЧата. Твоя задача отвечать студенту на учебные вопросы\n",
        "                Отвечай кратко и ёмко!\n",
        "                ## Шаблон ответа:\n",
        "                Запрос: {суммаризация запроса пользователя}.\n",
        "                Ответ: {ответ на запрос со списками, таблицами}.\n",
        "                Роли: {роли по информации запроса}.\n",
        "                ## Формат\n",
        "                Markdown\n",
        "                \"\"\"\n",
        "            )\n",
        "        ),\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.SYSTEM,\n",
        "            content=(\n",
        "                \"\"\"\n",
        "                Ты полезный ассистент для тестирования ГигаЧата. Твоя задача отвечать студенту на учебные вопросы\n",
        "                Отвечай кратко и ёмко!\n",
        "                ## Шаблон ответа:\n",
        "                {\n",
        "                  \"defenition\": \"\",\n",
        "                  \"properties\": \"\",\n",
        "                  \"roles\": \"\"\n",
        "                }\n",
        "                ## Формат\n",
        "                JSON\n",
        "                \"\"\"\n",
        "            )\n",
        "        ),\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        ),\n",
        "    ]"
      ],
      "metadata": {
        "id": "twj1-1ypgMKn"
      },
      "id": "twj1-1ypgMKn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ded0d7-c55d-43b3-82f8-8f6511106e24",
      "metadata": {
        "id": "f4ded0d7-c55d-43b3-82f8-8f6511106e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "e0066a25-f29a-481c-c853-899067080306"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\n{\n  \"definition\": \"Prompt Engineering — это процесс создания эффективных подсказок (prompt) для оптимизации работы моделей машинного обучения, особенно языковых моделей.\",\n  \"properties\": [\n    \"Точность формулировки запроса\",\n    \"Использование специальных маркеров и форматов данных\",\n    \"Тестирование различных вариантов подсказки\"\n  ],\n  \"roles\": \"Помогает достичь более точных и релевантных ответов от модели.\"\n}"
          },
          "metadata": {}
        }
      ],
      "source": [
        "payload = Chat(\n",
        "    messages=messages,\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        ")\n",
        "\n",
        "response = model.chat(payload)\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8050f0b9-75b9-4ad2-83ad-c612346f4b94",
      "metadata": {
        "id": "8050f0b9-75b9-4ad2-83ad-c612346f4b94"
      },
      "source": [
        "# Функции и Актуализация запросов к модели\n",
        "\n",
        "Языковые модели, включая `GigaChat`, обучены на данных, зафиксированных до определённой даты. Они не знают, что происходит «здесь и сейчас».\n",
        "Но если дать модели возможность вызвать функцию, которая получит свежие данные (например, через поисковик), — она сможет дать актуальный и точный ответ.\n",
        "\n",
        "[Механизм вызова функций](https://habr.com/ru/articles/806627/) называется `Function Calling` — механизм, при котором модель:\n",
        "* Решает, нужно ли вызвать функцию.\n",
        "* Формирует структурированный запрос к функции (с аргументами).\n",
        "* Система выполняет функцию.\n",
        "* Результат возвращается модели, и она формулирует финальный ответ.\n",
        "\n",
        "\n",
        "__Другими словами__ при использовании `Function Calling` в запрос передаётся не только история сообщений, но и список доступных функций.\n",
        "Модель анализирует контекст и решает:\n",
        "Ответить сразу, или вернуть специальное сообщение с `function_call`. Во втором случае будет необходимо вызвать функцию и повторно запросить модель.\n",
        "\n",
        "> Отметим, что не все модели подддерживают `Function Calling`.\n",
        "\n",
        "Создадим функцию  `search_ddg`, которая использует библиотеку `ddgs` для получения актуальных результатов поиска.\n",
        "Где `ddgs` — это библиотека для поиска в `DuckDuckGo`. `DuckDuckGo` выбран, потому что он не требует API-ключа."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef4894e5-aebe-40dc-bda2-f6c99c839a68",
      "metadata": {
        "id": "ef4894e5-aebe-40dc-bda2-f6c99c839a68"
      },
      "outputs": [],
      "source": [
        "def search_ddg(search_query):\n",
        "    \"\"\"Поиск в DuckDuckGo.\n",
        "        Полезен, когда нужно ответить на вопросы о текущих событиях.\n",
        "        Входными данными должен быть поисковый запрос.\"\"\"\n",
        "    return DDGS().text(search_query, max_results=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2d015e-bf0f-4239-9aa0-b2955430b534",
      "metadata": {
        "id": "0a2d015e-bf0f-4239-9aa0-b2955430b534",
        "outputId": "ff600e7f-358a-455d-e7c2-78f7008ec12d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'GISMETEO: Погода в Екатеринбурге сегодня, прогноз погоды ...', 'href': 'https://www.gismeteo.ru/weather-yekaterinburg-4517/', 'body': 'Погода в Екатеринбурге на сегодня , подробный прогноз погоды на сегодня для населенного пункта Екатеринбург , городской округ Екатеринбург , Свердловская область, Россия.'}\n"
          ]
        }
      ],
      "source": [
        "results = search_ddg(MESSAGE)\n",
        "print(results[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8759fdbc-0e1d-4869-97d6-292bf897c9a3",
      "metadata": {
        "id": "8759fdbc-0e1d-4869-97d6-292bf897c9a3"
      },
      "outputs": [],
      "source": [
        "search_func = Function(\n",
        "    name=\"duckduckgo_search\",\n",
        "    description=\"Поиск в DuckDuckGo для получения актуальной информации.\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\"query\": {\"type\": \"string\"}},\n",
        "        required=[\"query\"],\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4vbqWVKhSGkk"
      },
      "id": "4vbqWVKhSGkk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0da5d2fd-9e50-4286-8458-3d04fc662593",
      "metadata": {
        "id": "0da5d2fd-9e50-4286-8458-3d04fc662593",
        "outputId": "bb9208aa-50d0-484c-8b72-a4c667a26eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "role='assistant' content='' function_call=FunctionCall(name='duckduckgo_search', arguments={'query': 'prompt engineering определение и особенности'}) name=None attachments=None data_for_context=None functions_state_id='019ad592-1ac7-7c63-b0a1-f23e9c8cf492' reasoning_content=None id_=None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'function_call'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "messages = [\n",
        "        Messages(role=MessagesRole.USER, content=MESSAGE)\n",
        "    ]\n",
        "chat = Chat(messages=messages, functions=[search_func])\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "print(message)\n",
        "resp.finish_reason"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d749f3-6904-43cf-a895-440fd1250010",
      "metadata": {
        "id": "b4d749f3-6904-43cf-a895-440fd1250010",
        "outputId": "0d9c70fd-fb05-486c-e98b-e3120978fd91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\n**Prompt engineering** — это процесс структурирования или составления запроса таким образом, чтобы улучшить качество выходного результата от модели искусственного интеллекта (ИИ). \n\n### Особенности prompt engineering:\n\n1. **Четкость формулировки:** Важно создавать ясные и конкретные инструкции, чтобы направлять модель к нужному результату.\n   \n2. **Контекстуальность:** Добавление релевантной информации помогает модели лучше понимать контекст и формировать более точные ответы.\n\n3. **Итеративность:** Процесс часто включает многократное тестирование и уточнение запроса, чтобы достичь наилучшего возможного результата."
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Если модель хочет вызвать функцию\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func_name = message.function_call.name\n",
        "    query = message.function_call.arguments[\"query\"]\n",
        "\n",
        "    # Выполняем функцию\n",
        "    result = search_ddg(query)\n",
        "\n",
        "    # Шаг 2: отправляем результат обратно модели\n",
        "    messages.extend([\n",
        "        message,  # сообщение с function_call\n",
        "        Messages(role=MessagesRole.FUNCTION, content=json.dumps({\"result\": result}, ensure_ascii=False))\n",
        "    ])\n",
        "    final_resp = model.chat(Chat(messages=messages)).choices[0]\n",
        "    response = final_resp.message.content\n",
        "else:\n",
        "    # Модель ответила сразу\n",
        "    print('МОДЕЛЬ ОТВЕТИЛА СРАЗУ')\n",
        "    response = message.content\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "330c2c47-3f53-46e4-90f0-1e805f8b4213",
      "metadata": {
        "id": "330c2c47-3f53-46e4-90f0-1e805f8b4213"
      },
      "source": [
        "### Упражения\n",
        "1. Измените поле `desription` описания функции, например на\n",
        "    * \"Используй ТОЛЬКО для вопросов о погоде.\"\n",
        "    * \"Никогда не используй этот поиск.\"\n",
        "    * \"Это функция для поиска рецептов блюд.\"\n",
        "Проверьте как это скажется на результатах.\n",
        "2. Измените значение `max_results` в диапазоне 1 - 10, провеврьте как это скажется на качестве ответа\n",
        "3. Добавьте к примеру системный промпт, например \"Ты — помощник, который ВСЕГДА ищет информацию в интернете, даже если знаешь ответ.\"\n",
        "4. Добавьте функцию текущей даты к списку функций запроса.\n",
        "```python\n",
        "   def get_current_date():\n",
        "        \"\"\"Возвращает текущую дату в формате ГГГГ-ММ-ДД.\"\"\"\n",
        "        from datetime import datetime\n",
        "        return datetime.now().strftime(\"%Y-%m-%d\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_current_date():\n",
        "  from datetime import datetime\n",
        "  now = datetime.now()\n",
        "  today = datetime(year=now.year, month=now.month+1, day=5)\n",
        "  return today.strftime(\"%Y-%m-%d\")"
      ],
      "metadata": {
        "id": "a8VMnnDun0CY"
      },
      "id": "a8VMnnDun0CY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_current_date())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__jXjFNsn-GB",
        "outputId": "2f73c9f3-c252-40b1-9ade-f99037b9d850"
      },
      "id": "__jXjFNsn-GB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_func = Function(\n",
        "    name=\"get_current_date\",\n",
        "    description=\"Узнать дату сегодня (сегодняшний день, сегодняшнее число)\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={},\n",
        "        required=[],\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "RoThkfp0oAnX"
      },
      "id": "RoThkfp0oAnX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_func = [\n",
        "    Function(\n",
        "      name=\"duckduckgo_search\",\n",
        "      description=\"Поиск в DuckDuckGo для получения актуальной информации. Используй ТОЛЬКО для погоды и даты\",\n",
        "      parameters=FunctionParameters(\n",
        "          type=\"object\",\n",
        "          properties={\"query\": {\"type\": \"string\"}},\n",
        "          required=[\"query\"],\n",
        "          )\n",
        "    ),\n",
        "    Fucntion(\n",
        "      name=\"get_current_date\",\n",
        "      description=\"Узнать дату сегодня (сегодняшний день, сегодняшнее число)\",\n",
        "      parameters=FunctionParameters(\n",
        "          type=\"object\",\n",
        "          properties={},\n",
        "          required=[],\n",
        "        ),\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "W6jgnXjYmJ-7",
        "outputId": "5b3f3aa4-90d5-44d9-a3f9-dcf93a95896f"
      },
      "id": "W6jgnXjYmJ-7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "keyword argument repeated: name (ipython-input-4086365309.py, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4086365309.py\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    name=\"get_current_date\",\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated: name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8350c04-5208-4cf8-95d7-ecd64e3db3b3",
      "metadata": {
        "id": "e8350c04-5208-4cf8-95d7-ecd64e3db3b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df1322d8-bd51-4143-da51-7319e44b60b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "role='assistant' content='' function_call=FunctionCall(name='get_current_date', arguments={}) name=None attachments=None data_for_context=None functions_state_id='019ad5a6-f225-7be9-b2d1-e7396283682b' reasoning_content=None id_=None\n"
          ]
        }
      ],
      "source": [
        "MESSAGE = \"Какое сегодня число?\"\n",
        "\n",
        "messages = [\n",
        "        Messages(role=MessagesRole.USER, content=MESSAGE)\n",
        "    ]\n",
        "\n",
        "chat = Chat(messages=messages, functions=search_func, max_tokens=100)\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "print(message)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Если модель хочет вызвать функцию\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func_name = message.function_call.name\n",
        "\n",
        "    # Выполняем функцию\n",
        "    if func_name == \"duckduckgo_search\":\n",
        "      query = message.function_call.arguments[\"query\"]\n",
        "      result = search_ddg(query)\n",
        "    elif func_name == \"get_current_date\":\n",
        "      result = get_current_date()\n",
        "\n",
        "    # Шаг 2: отправляем результат обратно модели\n",
        "    messages.extend([\n",
        "        message,  # сообщение с function_call\n",
        "        Messages(role=MessagesRole.FUNCTION, content=json.dumps({\"result\": result}, ensure_ascii=False))\n",
        "    ])\n",
        "    final_resp = model.chat(Chat(messages=messages)).choices[0]\n",
        "    response = final_resp.message.content\n",
        "else:\n",
        "    # Модель ответила сразу\n",
        "    print('МОДЕЛЬ ОТВЕТИЛА СРАЗУ')\n",
        "    response = message.content\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "T4j4F5JMoVFF",
        "outputId": "dc62912e-5f52-4d0e-be68-38c7d8061ac2"
      },
      "id": "T4j4F5JMoVFF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\nСегодня 5 декабря 2025 года."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4778da43-9f46-49e8-8c6b-dcbeab29fa6a",
      "metadata": {
        "id": "4778da43-9f46-49e8-8c6b-dcbeab29fa6a"
      },
      "source": [
        "## Упражения 2\n",
        "\n",
        "Создадим свой калькулятор при помощи функций `GigaChat`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dda6449-cdb8-422e-923d-329572489166",
      "metadata": {
        "id": "6dda6449-cdb8-422e-923d-329572489166"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def safe_calculate(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Выполняет математическое выражение.\n",
        "    Поддерживает: +, -, *, /, **, скобки, числа с точкой.\n",
        "    Безопасен: разрешает ТОЛЬКО математические символы.\n",
        "    \"\"\"\n",
        "    # Разрешённые символы: цифры, операторы, скобки, точка, пробелы\n",
        "    if not re.fullmatch(r'[\\d+\\-*/().\\s]+', expression):\n",
        "        return \"Ошибка: выражение содержит недопустимые символы.\"\n",
        "\n",
        "    try:\n",
        "        # Ограничиваем сложность (например, не даём выполнить 9**9**9)\n",
        "        if '^' in expression or len(expression) > 50:\n",
        "            return \"Ошибка: выражение слишком сложное или длинное.\"\n",
        "\n",
        "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
        "        return str(result)\n",
        "    except Exception as e:\n",
        "        return f\"Ошибка вычисления: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4387a9e3-15cc-416e-bd0d-87107b8f7178",
      "metadata": {
        "id": "4387a9e3-15cc-416e-bd0d-87107b8f7178",
        "outputId": "2c2d6d8c-73f6-4590-e202-a58fd68c7160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'243'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "safe_calculate('3*(4+5)**2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ccfa93f-9a97-41fb-ae91-7acca80eadb6",
      "metadata": {
        "id": "7ccfa93f-9a97-41fb-ae91-7acca80eadb6"
      },
      "outputs": [],
      "source": [
        "calculate_func = Function(\n",
        "    name=\"calculate\",\n",
        "    description=\"Выполняет математические вычисления. Передавай ТОЛЬКО выражение в виде строки, например: '2 + 3 * 4'.\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\n",
        "            \"expression\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Математическое выражение (только цифры, +, -, *, /, **, скобки)\"\n",
        "            }\n",
        "        },\n",
        "        required=[\"expression\"],\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01bbf602-9bf9-421e-aeab-cb882584e722",
      "metadata": {
        "id": "01bbf602-9bf9-421e-aeab-cb882584e722"
      },
      "outputs": [],
      "source": [
        "message = 'Сколько будет 3*(4+5)**2'\n",
        "\n",
        "messages = [\n",
        "    Messages(role=MessagesRole.USER, content=message)\n",
        "]\n",
        "\n",
        "chat = Chat(messages=messages, functions=[calculate_func])\n",
        "\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func = message.function_call\n",
        "    if func.name == \"calculate\":\n",
        "        expr = func.arguments.get(\"expression\", \"\")\n",
        "        result = safe_calculate(expr)\n",
        "        # Возвращаем результат модели\n",
        "        messages.extend([\n",
        "            message,\n",
        "            Messages(role=MessagesRole.FUNCTION, content=result)\n",
        "        ])\n",
        "        # Получаем финальный ответ\n",
        "        final = model.chat(Chat(messages=messages)).choices[0]\n",
        "        response =  final.message.content\n",
        "else:\n",
        "    # Модель ответила без вычислений (например, объяснила задачу)\n",
        "    response = message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f920ef5-e42d-4419-957e-66ce8b60cd75",
      "metadata": {
        "id": "3f920ef5-e42d-4419-957e-66ce8b60cd75",
        "outputId": "13adbbb8-fa76-4b5b-bd63-c0a7c01f0123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\nРешим выражение пошагово:\n\n1. Сначала выполним действие в скобках:  \n$4 + 5 = 9$\n\n2. Возведём полученное число в квадрат:  \n$9^2 = 81$\n\n3. Теперь умножим результат на 3:  \n$3 \\cdot 81 = 243$\n\n**Итоговый ответ:** $\\mathbf{243}$"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(\"<blockquote>\\n\\n\"+response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b42ecb18-022c-4307-8c63-a431b8213837",
      "metadata": {
        "id": "b42ecb18-022c-4307-8c63-a431b8213837"
      },
      "source": [
        "__Упражения__\n",
        "1. Сделайте проверку на sin/cos в функции калькулятора\n",
        "   \n",
        "2. Расширьте функционал калькулятора"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_func = Function(\n",
        "    name=\"calculate\",\n",
        "    description=\"Выполняет математические вычисления. Передавай ТОЛЬКО выражение в виде строки, например: '2 + 3 * 4'.\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\n",
        "            \"expression\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Математическое выражение (только цифры, +, -, *, /, **, скобки)\"\n",
        "            }\n",
        "        },\n",
        "        required=[\"expression\"],\n",
        "    )\n",
        ")\n",
        "\n",
        "sin_func = Function(\n",
        "    name=\"sin\",\n",
        "    description=\"Находит синус выражения. ВАЖНО, сначала высчитай синусы, потом замени синусы на реальные значения и передай аргумент функции калькулятора\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\n",
        "            \"value\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Значение угла в радианах\"\n",
        "            }\n",
        "        },\n",
        "        required=[\"value\"],\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "kZza6pPdsU2s"
      },
      "id": "kZza6pPdsU2s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = 'Сколько будет 55*243?'\n",
        "\n",
        "messages = [\n",
        "    Messages(role=MessagesRole.USER, content=message)\n",
        "]\n",
        "\n",
        "chat = Chat(messages=messages, functions=[calculate_func, sin_func], max_tokens=100)\n",
        "\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func = message.function_call\n",
        "    if func.name == \"calculate\":\n",
        "        print(\"Калькулирую!\")\n",
        "        expr = func.arguments.get(\"expression\", \"\")\n",
        "        result = safe_calculate(expr)\n",
        "    elif func.name == \"sin\":\n",
        "        value = func.arguments.get(\"value\", \"\")\n",
        "        print(\"Расчёты!\")\n",
        "        result = eval(f\"sin({value})\")\n",
        "    # Возвращаем результат модели\n",
        "    messages.extend([\n",
        "        message,\n",
        "        Messages(role=MessagesRole.FUNCTION, content=result)\n",
        "    ])\n",
        "    # Получаем финальный ответ\n",
        "    final = model.chat(Chat(messages=messages)).choices[0]\n",
        "    response =  final.message.content\n",
        "else:\n",
        "    # Модель ответила без вычислений (например, объяснила задачу)\n",
        "    response = message.content"
      ],
      "metadata": {
        "id": "GICchSqBs-Qp",
        "outputId": "0ace3a22-d801-41ac-87ce-e13cb092799b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GICchSqBs-Qp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Калькулирую!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "PQJ0J2k9vD3N",
        "outputId": "47c85308-7c83-45e7-f205-439af5b0e047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PQJ0J2k9vD3N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Произведение чисел 55 и 243 равно $ \\fbox{13365} $.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d09d2294-0782-460f-bfdc-dc3cd52c125f",
      "metadata": {
        "id": "d09d2294-0782-460f-bfdc-dc3cd52c125f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c9f966b-3596-4846-d280-e0b0d5636609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.0\n"
          ]
        }
      ],
      "source": [
        "from math import sin, cos, pi\n",
        "print(sin(3*pi/2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de6e24ea-1c04-4a74-bf83-9d69a5adf892",
      "metadata": {
        "id": "de6e24ea-1c04-4a74-bf83-9d69a5adf892"
      },
      "source": [
        "# <span style=\"color:red\">Опционально.</span> О более продвинутом пути к LLM-приложениям"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_gigachat"
      ],
      "metadata": {
        "id": "q36DqYcbxDZA",
        "outputId": "93a7477a-017e-4611-b9d0-383e0631c930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "id": "q36DqYcbxDZA",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_gigachat\n",
            "  Downloading langchain_gigachat-0.3.12-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: gigachat<0.2.0,>=0.1.41.post1 in /usr/local/lib/python3.12/dist-packages (from langchain_gigachat) (0.1.43)\n",
            "Collecting langchain-core<0.4,>=0.3 (from langchain_gigachat)\n",
            "  Downloading langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting types-requests<3.0,>=2.32 (from langchain_gigachat)\n",
            "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: httpx<1 in /usr/local/lib/python3.12/dist-packages (from gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1 in /usr/local/lib/python3.12/dist-packages (from gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (2.12.3)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (0.4.59)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (25.0)\n",
            "Requirement already satisfied: urllib3>=2 in /usr/local/lib/python3.12/dist-packages (from types-requests<3.0,>=2.32->langchain_gigachat) (2.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<0.4,>=0.3->langchain_gigachat) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (2.32.4)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (0.12.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (3.4.4)\n",
            "Downloading langchain_gigachat-0.3.12-py3-none-any.whl (27 kB)\n",
            "Downloading langchain_core-0.3.80-py3-none-any.whl (450 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.8/450.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, langchain-core, langchain_gigachat\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.1\n",
            "    Uninstalling langchain-core-1.2.1:\n",
            "      Successfully uninstalled langchain-core-1.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langgraph-prebuilt 1.0.5 requires langchain-core>=1.0.0, but you have langchain-core 0.3.80 which is incompatible.\n",
            "langchain 1.2.0 requires langchain-core<2.0.0,>=1.2.1, but you have langchain-core 0.3.80 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-0.3.80 langchain_gigachat-0.3.12 types-requests-2.32.4.20250913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "j9819xjLxfRu",
        "outputId": "6a2872e9-6d90-4905-8e6a-719967df6edb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "id": "j9819xjLxfRu",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Collecting langchain-core<2.0.0,>=1.2.1 (from langchain)\n",
            "  Downloading langchain_core-1.2.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.5.0)\n",
            "Downloading langchain_core-1.2.4-py3-none-any.whl (477 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m477.4/477.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.80\n",
            "    Uninstalling langchain-core-0.3.80:\n",
            "      Successfully uninstalled langchain-core-0.3.80\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-gigachat 0.3.12 requires langchain-core<0.4,>=0.3, but you have langchain-core 1.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBbVejG6jN3V",
        "outputId": "bbe3c9ee-7f4b-441d-d544-7b6e53835530",
        "collapsed": true
      },
      "id": "cBbVejG6jN3V",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.59)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-text-splitters-1.1.0 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "57a311e9-7a90-4aef-801e-010ec53b3e89",
      "metadata": {
        "id": "57a311e9-7a90-4aef-801e-010ec53b3e89"
      },
      "outputs": [],
      "source": [
        "from langchain_gigachat import GigaChat\n",
        "# from langchain_core.tools import tool\n",
        "# from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, FunctionMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "219a10ac-9507-43eb-90f8-9143b709ded6",
      "metadata": {
        "id": "219a10ac-9507-43eb-90f8-9143b709ded6"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "62cc963b-0bd4-4683-b651-16903e4bdb0f",
      "metadata": {
        "id": "62cc963b-0bd4-4683-b651-16903e4bdb0f"
      },
      "outputs": [],
      "source": [
        "# Инициализация модели\n",
        "llm = GigaChat(\n",
        "    model=\"GigaChat-2\",\n",
        "    credentials=auth,\n",
        "    verify_ssl_certs=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1930148-9153-4ad6-8acb-89f101e98a13",
      "metadata": {
        "id": "a1930148-9153-4ad6-8acb-89f101e98a13"
      },
      "source": [
        "В `Langchain` есть классы `HumanMessage`, `SystemMessage` и `AssistantMessage` для удобного представления словарей сообщений.\n",
        "\n",
        "Например вмето записи сообщания в стиле:\n",
        "```json\n",
        "{'role': 'system',\n",
        "'content': 'Отвечай как бывалый пират. Пусть тебя зовут Генри Морган.'\n",
        "}\n",
        "```\n",
        "теперь можем записать:\n",
        "```python\n",
        "SystemMessage(content='Отвечай как бывалый пират. Пусть тебя зовут Генри Морган.')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "812ee915-ffd2-405f-acda-fedcf7fb476d",
      "metadata": {
        "id": "812ee915-ffd2-405f-acda-fedcf7fb476d"
      },
      "outputs": [],
      "source": [
        "msg = [SystemMessage(content='Отвечай как инженр-датасаинтист с 20 летним опытом. Используй Markdown разметку ответа. Ответ не должен быть длинее 10 строк')]\n",
        "\n",
        "question = \"Какие приемущества может дать langchain в работе с GigaChat\"\n",
        "\n",
        "msg.append(HumanMessage(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "396a1ef5-a52c-459e-9ec8-0b1f1e6ca97d",
      "metadata": {
        "scrolled": true,
        "id": "396a1ef5-a52c-459e-9ec8-0b1f1e6ca97d",
        "outputId": "e06807a5-5d59-4306-8e14-cbb53c100a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\n**Преимущества использования LangChain с GigaChat:**\n\n- **Модульность и гибкость:** возможность интегрировать различные инструменты (векторы, цепочки шагов, облачные хранилища и т.д.) для построения сложных решений.\n- **Простота разработки:** упрощает создание и интеграцию цепочек обработки данных вокруг моделей ИИ типа GigaChat.\n- **Интеграция сторонних библиотек:** поддержка работы с внешними API и базами знаний через собственные интеграции.\n- **Управление потоком выполнения:** позволяет контролировать последовательность действий и логику выполнения задач на основе контекста.\n- **Обработка и"
          },
          "metadata": {}
        }
      ],
      "source": [
        "results = llm.invoke(msg).content[:600]\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+results))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e36f412e-86b4-46d9-8283-db22049ef71a",
      "metadata": {
        "id": "e36f412e-86b4-46d9-8283-db22049ef71a"
      },
      "source": [
        "При помощи класса `AIMessage` `LangChain` позволяет сохранить ответ на первое сообщение и использовать этот результат при вторичном запросе. В нашем случае попросим уточнить `GigaChat` примеры кода для нашего запроса.\n",
        "\n",
        "В примере будем использовать метод `invoke` - часть унифицированного `Runnable API (LangChain 0.1.0+)`.\n",
        "Прямой вызов - устаревший подход, может быть удален в будущем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9b7d1357-6954-4d58-9b10-92b6d57314e5",
      "metadata": {
        "scrolled": true,
        "id": "9b7d1357-6954-4d58-9b10-92b6d57314e5",
        "outputId": "0a5e55d6-47e1-422b-9bbd-67fdf8e0a5d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\n# **Пример использования цепочки (Chain) с GigaChat (LangChain-GigaChat)**\n\n## 📌 Пример задачи:\nНужно разработать простую систему обработки запроса пользователя на основе информации из заранее загруженных текстов (например, инструкции или справочной документации).\n\n## 🛠 Реализация\n\n```python\nfrom langchain_gigachat import GigachatChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import HuggingFaceEmbeddings\n\n# Загрузка текста\ntext = \"...\"\ntext_splitter = CharacterTextSplitter()\ndocs = text_splitter.split_text(text)\n\n# Создание векторной базы данных\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\nvectorstore = FAISS.from_documents(docs, embeddings)\n\n# Создание цепочки (Chain)\nprompt_template = \"\"\"Используя предоставленную информацию, ответьте на вопрос пользователя:\n{query}\n\"\"\"\nprompt = PromptTemplate(template=prompt_template, input_variables=[\"query\"])\n\nchain = GigachatChain(\n    prompt=prompt,\n    vectorstore=vectorstore,\n    k=3  # количество документов для поиска\n)\n\n# Запрос пользователя\nquestion = \"Как установить программу?\"\nresponse = chain.run(question)\nprint(response)\n```\n\n## 💡 **Комментарии к коду:**\n\n- `CharacterTextSplitter` разбивает текст на фрагменты подходящего размера для эффективной работы с моделями.\n- `FAISS` используется для хранения и быстрого поиска релевантных фрагментов текста по запросам.\n- `HuggingFaceEmbeddings` обеспечивает векторизацию текста для эффективного сопоставления запросов и ответов.\n- `GigachatChain` — это специализированный класс от LangChain, предназначенный для интеграции с GigaChat API, позволяющий выполнять запросы пользователю и использовать результаты из векторной базы данных.\n\nТаким образом, цепочка позволяет объединить естественное общение через GigaChat и эффективный поиск информации из заранее подготовленных источников."
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Получаем ответ\n",
        "response = llm.invoke(msg)  # Используем invoke вместо прямого вызова\n",
        "results = response.content[:600]\n",
        "\n",
        "# Сохраняем ответ в историю\n",
        "msg.append(AIMessage(content=results))\n",
        "\n",
        "# Пример продолжения диалога с историей\n",
        "follow_up_question = \"Можешь привести конкретный пример использования цепочки (chain) с GigaChat (langchain_gigachat)?\"\n",
        "msg.append(HumanMessage(content=follow_up_question))\n",
        "\n",
        "# Получаем ответ с учетом всей истории\n",
        "follow_up_response = llm.invoke(msg)\n",
        "msg.append(AIMessage(content=follow_up_response.content))\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+follow_up_response.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "502c9b23-24bc-4ca2-ab8f-0fa4b91c9fcf",
      "metadata": {
        "id": "502c9b23-24bc-4ca2-ab8f-0fa4b91c9fcf"
      },
      "source": [
        "Попробуем также в целях демонстрации возможностей `langchain` создать цепочку рассуджений. Для этого воспользуемся специальным классом `PromptTemplate`, который позволяет создавать шаблоны запросов аналогично f-функциям"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "662eef72-9eba-4ddf-b8fe-405355191356",
      "metadata": {
        "id": "662eef72-9eba-4ddf-b8fe-405355191356",
        "outputId": "fd3b1a65-36e8-437c-f89c-0f1a15e1acd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Задача:\n** В классе 30 учеников. 40% из них - девочки. Сколько мальчиков в классе?\n----------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Решение:\n\n** content='### Шаг 1. Понимание условия задачи\\n\\nНам известно общее количество учеников в классе — **30 человек**. Из них **40%** составляют девочки. Нам нужно определить количество мальчиков в классе.\\n\\n### Шаг 2. Логическое разложение решения\\n\\nЧтобы узнать количество девочек, сначала найдем процентное выражение от общего числа учеников (это будет число девочек). Затем вычтем полученное значение из общего количества учеников, чтобы получить количество мальчиков.\\n\\n### Шаг 3. Вычисление количества девочек\\n\\n- Общее количество учеников = 30.\\n- Процент девочек = 40%.\\n- Количество девочек = (процент девочек / 100%) × общее количество учеников.\\n\\n$$\\n\\\\text{Количество девочек} = \\\\frac{40}{100} \\\\times 30 = 0.4 \\\\times 30 = 12\\n$$\\n\\n### Шаг 4. Определение количества мальчиков\\n\\nТеперь мы знаем, сколько девочек в классе, осталось найти количество мальчиков. Используем формулу:\\n\\n$$\\n\\\\text{Количество мальчиков} = \\\\text{Общее количество учеников} - \\\\text{Количество девочек}\\n$$\\n\\n$$\\n\\\\text{Количество мальчиков} = 30 - 12 = 18\\n$$\\n\\n### Шаг 5. Проверка правильности рассуждений\\n\\nПроверим правильность вычислений:\\n- Девочек в классе должно быть 40%, значит 40% от 30 учеников составляет ровно 12 человек.\\n- Если 12 учеников — девочки, тогда оставшихся учеников (30 − 12) действительно будут мальчиками, и получается 18 мальчиков.\\n\\n### Окончательный ответ\\n\\nТаким образом, в классе **18 мальчиков**.' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 98, 'completion_tokens': 355, 'total_tokens': 453, 'precached_prompt_tokens': 3}, 'model_name': 'GigaChat-2:2.0.28.2', 'x_headers': {'x-request-id': '1efc8332-b2ed-4d7b-9fe4-d9cf33b36ad5', 'x-session-id': '50dd52ce-40de-4ca1-a1c8-aa13c8672cd3', 'x-client-id': None}, 'finish_reason': 'stop'} id='1efc8332-b2ed-4d7b-9fe4-d9cf33b36ad5' usage_metadata={'output_tokens': 355, 'input_tokens': 98, 'total_tokens': 453, 'input_token_details': {'cache_read': 3}}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Задача:\n** Книга стоит 500 рублей. После скидки цена снизилась на 20%. Сколько стоит книга после скидки?\n----------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Решение:\n\n** content='### Шаг 1. Понимание условия задачи\\n\\n- Дано: стоимость книги до скидки — **500 рублей**.\\n- Необходимо узнать: сколько будет стоить книга после скидки, размер которой составляет **20% от первоначальной цены**.\\n\\n### Шаг 2. Разбиваем решение на логические шаги\\n\\n1. Вычисляем сумму скидки (в рублях).\\n2. Избавляемся от скидки, вычитая её из первоначальной стоимости книги.\\n\\n### Шаг 3. Выполняем вычисления\\n\\n#### 1. Определение суммы скидки:\\nСумма скидки = 20% от 500 рублей\\n$$\\n\\\\text{Скидка} = 0,20 \\\\times 500 = 100\\\\ руб.\\n$$\\n\\n#### 2. Расчёт итоговой стоимости книги после скидки:\\nПервоначальная стоимость минус скидка:\\n$$\\n\\\\text{Цена после скидки} = 500 - 100 = 400\\\\ руб.\\n$$\\n\\n### Шаг 4. Проверяем правильность рассуждений\\n\\n- Первоначальная сумма скидки (20%) правильно посчитана: $0,20 \\\\times 500 = 100$.\\n- Итоговая цена книги корректно получена вычитанием скидки из первоначальной стоимости.\\n\\n### Шаг 5. Формулируем окончательный ответ\\n\\nПосле скидки в размере 20%, книга будет стоить **400 рублей**.' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 101, 'completion_tokens': 303, 'total_tokens': 404, 'precached_prompt_tokens': 3}, 'model_name': 'GigaChat-2:2.0.28.2', 'x_headers': {'x-request-id': 'f0d10193-b2a9-44ed-8496-6ebcbdc4eb29', 'x-session-id': '706600cc-be33-4990-98dc-56e8340474b9', 'x-client-id': None}, 'finish_reason': 'stop'} id='f0d10193-b2a9-44ed-8496-6ebcbdc4eb29' usage_metadata={'output_tokens': 303, 'input_tokens': 101, 'total_tokens': 404, 'input_token_details': {'cache_read': 3}}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Создаем шаблон для Chain of Thought\n",
        "cot_template = \"\"\"\n",
        "Реши задачу шаг за шагом:\n",
        "\n",
        "Задача: {problem}\n",
        "\n",
        "Пожалуйста:\n",
        "1. Сначала пойми, что дано и что нужно найти\n",
        "2. Разбей решение на логические шаги\n",
        "3. Выполни вычисления для каждого шага\n",
        "4. Проверь правильность рассуждений\n",
        "5. Сформулируй окончательный ответ\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cot_prompt = ChatPromptTemplate.from_template(\n",
        "    cot_template\n",
        ")\n",
        "\n",
        "cot_chain = cot_prompt | llm  # создание цепочки через pipe\n",
        "\n",
        "# Создаем цепочку\n",
        "# cot_chain = LLMChain(llm=llm, prompt=cot_prompt)\n",
        "# news = \"Вчера в Екатеринбурге произошло 3 ДТП и прорвало трубу на Ленина.\"\n",
        "# response = cot_chain.invoke({\"news_text\": news})\n",
        "# print(response.content)\n",
        "\n",
        "# Используем\n",
        "problems = [\n",
        "    \"В классе 30 учеников. 40% из них - девочки. Сколько мальчиков в классе?\",\n",
        "    \"Книга стоит 500 рублей. После скидки цена снизилась на 20%. Сколько стоит книга после скидки?\",\n",
        "]\n",
        "\n",
        "for problem in problems:\n",
        "    result = cot_chain.invoke(problem)\n",
        "    display(Markdown(f\"**Задача:\\n** {problem}\\n----------------------------\"))\n",
        "    display(Markdown(f\"**Решение:\\n\\n** {result}\"))\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dbd67a2-b43b-48f9-92fc-6606809084e8",
      "metadata": {
        "id": "9dbd67a2-b43b-48f9-92fc-6606809084e8"
      },
      "source": [
        "### Упражнение:\n",
        "\n",
        "Проверьте качество работы цепочки рассуждений для разных категорий вопросов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca45eef-48b9-46e2-be61-877e56d11b06",
      "metadata": {
        "id": "fca45eef-48b9-46e2-be61-877e56d11b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "outputId": "3ff08b3f-d997-4777-c7a5-26ac60f09f4d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Задача:\n** Каков радиус Земли?\n----------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Шаг 1. Понимание условия задачи\n\nНам дана задача определения радиуса Земли. Нам известно следующее:\n- Земля имеет форму близкую к сферической (геоидной).\n- В большинстве случаев для расчетов используют средний радиус Земли.\n\nНеобходимо определить этот средний радиус.\n\n## Шаг 2. Разбиение решения на логические шаги\n\n1. **Определение среднего радиуса Земли**  \n   Для большинства практических целей используется среднее значение радиуса Земли.\n   \n2. **Формула расчета среднего радиуса**:  \n   Формула для средней окружности сферы ($C$) известна из геометрии:  \n\n$$\n   C = 2\\pi R,\n$$\n\n   где $R$ — радиус сферы.\n\n   Из этой формулы мы можем выразить радиус через длину окружности:\n\n$$\n   R = \\frac{C}{2\\pi}\n$$\n\n3. **Средняя длина окружности Земли**  \n   Среднюю длину окружности Земли принимают равной примерно $40\\,075$ км (среднее расстояние от экватора до полюса).\n\n## Шаг 3. Вычисление среднего радиуса Земли\n\nИспользуем формулу, выражающую радиус через среднюю длину окружности:\n\n$$\nR = \\frac{40\\,075\\,\\text{км}}{2\\pi}\n$$\n\nВычислим значение:\n\n$$\nR = \\frac{40\\,075}{2 \\times 3.1416} \\approx \\frac{40\\,075}{6.2832} \\approx 6\\,371\\,\\text{км}\n$$\n\n## Шаг 4. Проверка правильности рассуждений\n\nПроверим корректность полученного результата:\n- Использована стандартная формула длины окружности.\n- Подставлено известное среднее значение длины окружности Земли.\n- Все вычисления произведены правильно.\n\n## Шаг 5. Окончательный ответ\n\nРадиус Земли составляет приблизительно $6\\,371$ километр."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n"
          ]
        }
      ],
      "source": [
        "problems = [\n",
        "    \"Каков радиус Земли?\"\n",
        "]\n",
        "\n",
        "for problem in problems:\n",
        "    result = cot_chain.invoke(problem)\n",
        "    display(Markdown(f\"**Задача:\\n** {problem}\\n----------------------------\"))\n",
        "    display(Markdown(result.content))\n",
        "    print(\"---\")\n",
        "\n",
        "problems = [\n",
        "    \"Рецепт пельменей\"\n",
        "]\n",
        "\n",
        "for problem in problems:\n",
        "    result = cot_chain.invoke(problem)\n",
        "    display(Markdown(f\"**Задача:\\n** {problem}\\n----------------------------\"))\n",
        "    display(Markdown(result.content))\n",
        "    print(\"---\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}