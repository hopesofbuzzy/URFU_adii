{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hopesofbuzzy/URFU_adii/blob/main/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B8/11/06_PromptEng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c23371a-3f67-4e0d-be8d-a69967daa3a4",
      "metadata": {
        "id": "5c23371a-3f67-4e0d-be8d-a69967daa3a4"
      },
      "source": [
        "# Работа с LLM GigaChat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gigachat\n",
        "!pip install ddgs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OpshkKS5W2L",
        "outputId": "5ba2c6a1-081a-4a6a-845b-e9a3a36d577b",
        "collapsed": true
      },
      "id": "3OpshkKS5W2L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gigachat in /usr/local/lib/python3.12/dist-packages (0.1.43)\n",
            "Requirement already satisfied: httpx<1 in /usr/local/lib/python3.12/dist-packages (from gigachat) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1 in /usr/local/lib/python3.12/dist-packages (from gigachat) (2.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1->gigachat) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75744f8-59dd-429a-94b7-442f4f06fc7e",
      "metadata": {
        "id": "c75744f8-59dd-429a-94b7-442f4f06fc7e"
      },
      "outputs": [],
      "source": [
        "from gigachat import GigaChat\n",
        "from gigachat.models import Chat, Function, FunctionParameters, Messages, MessagesRole\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18c08934-96f1-44a3-8a35-ed7068751302",
      "metadata": {
        "id": "18c08934-96f1-44a3-8a35-ed7068751302"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from ddgs import DDGS\n",
        "\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client_id = userdata.get('SBER_ID')\n",
        "secret = userdata.get('SBER_SECRET')\n",
        "auth = userdata.get('SBER_AUTH')\n",
        "\n",
        "import base64\n",
        "credentials = f\"{client_id}:{secret}\"\n",
        "print(credentials)\n",
        "encoded_credentials = base64.b64encode(credentials.encode('utf-8')).decode('utf-8')\n",
        "\n",
        "\n",
        "encoded_credentials == auth"
      ],
      "metadata": {
        "id": "v3n9TJfP9xxJ"
      },
      "id": "v3n9TJfP9xxJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f74e41a-be15-4690-b439-4a0bf9ea1f63",
      "metadata": {
        "id": "9f74e41a-be15-4690-b439-4a0bf9ea1f63"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d6420c-d727-45aa-89a2-2379a852fd4f",
      "metadata": {
        "id": "17d6420c-d727-45aa-89a2-2379a852fd4f"
      },
      "outputs": [],
      "source": [
        "MESSAGE = \"Привет!\"\n",
        "with GigaChat(credentials=auth, verify_ssl_certs=False) as giga:\n",
        "    response = giga.chat(MESSAGE)\n",
        "    content = response.choices[0].message.content\n",
        "    display(Markdown(\"<blockquote>\\n\\n\"+content))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad6179e8-5d6b-4113-b673-d642dbfae6ea",
      "metadata": {
        "id": "ad6179e8-5d6b-4113-b673-d642dbfae6ea"
      },
      "source": [
        "______________________________________________________\n",
        "\n",
        "Перейдем к выбору моделей. Актуальный список моделей можно найти [тут](https://developers.sber.ru/docs/ru/gigachat/models). Модели могут отличатся качеством и разнообразием ответов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3206700-7371-493b-b20b-93c7a810d9f1",
      "metadata": {
        "scrolled": true,
        "id": "b3206700-7371-493b-b20b-93c7a810d9f1"
      },
      "outputs": [],
      "source": [
        "model = GigaChat(\n",
        "    model=\"GigaChat-2\",\n",
        "    credentials=auth,\n",
        "    verify_ssl_certs=False\n",
        ")\n",
        "\n",
        "\n",
        "# response = model.chat(MESSAGE)\n",
        "# content = response.choices[0].message.content\n",
        "# # print(content)\n",
        "# display(Markdown(\"<blockquote>\\n\\n\"+content))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e96d3c1-7b1e-41e5-98a6-8ed16772f6d2",
      "metadata": {
        "id": "0e96d3c1-7b1e-41e5-98a6-8ed16772f6d2"
      },
      "source": [
        "### Упражнения\n",
        "1. Предложите промпт, требующий знания информации на текущую дату, на дату несколько лет назад и на достаточно известное историческое событие, сравните и объясните результаты.\n",
        "2. Проверить качество результата запросов по категориям: математика, естественные науки, гуманитарные науки для разных моделей.\n",
        "3. Создайте небольшой диалог двух ИИ-персон"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebb17067-a6b8-4eef-b99e-32525d14c29b",
      "metadata": {
        "id": "ebb17067-a6b8-4eef-b99e-32525d14c29b"
      },
      "outputs": [],
      "source": [
        "with GigaChat(credentials=auth, model=\"GigaChat-2\", verify_ssl_certs=False) as giga:\n",
        "  response = giga.chat(\"Когда случился Коронавирус\")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "DV2u3g6qB4_d"
      },
      "id": "DV2u3g6qB4_d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52e77a02-3307-4eaa-b9f1-9eedff40cea4",
      "metadata": {
        "id": "52e77a02-3307-4eaa-b9f1-9eedff40cea4"
      },
      "outputs": [],
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=\"Объясни, что такое AI-agent?\"\n",
        "        ),\n",
        "]\n",
        "\n",
        "payload = Chat(\n",
        "    messages=messages,\n",
        "    temperature=0.7,\n",
        "    max_tokens=100,\n",
        ")\n",
        "\n",
        "print(\"Объясни, что такое AI-agent?\")\n",
        "for role in [MessagesRole.ASSISTANT, MessagesRole.USER]:\n",
        "  with GigaChat(credentials=auth, model=\"GigaChat-2\", verify_ssl_certs=False) as giga:\n",
        "    response = giga.chat(payload)\n",
        "    payload.messages.append(Messages(role=role, content=response.choices[0].message.content))\n",
        "    print(\"-----------------\")\n",
        "    display(Markdown(response.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5be346c-4b50-498e-a6c2-397067ceed27",
      "metadata": {
        "id": "a5be346c-4b50-498e-a6c2-397067ceed27"
      },
      "source": [
        "\n",
        "# Роли и контекст запроса\n",
        "\n",
        "\n",
        "Более правиьно формулировать запросы (`payload`) к модели с использованием объекта типа `Chat`.\n",
        "`Chat` — это объект, описывающий весь чат-запрос к модели. Он содержит:\n",
        "* `messages` — список сообщений, представляющих историю диалога.\n",
        "* `temperature` — параметр, управляющий «творчеством» модели:\n",
        "    * Чем ближе температурак `0`, тем более детерминированный и предсказуемый ответ.\n",
        "    * Чем ближе температура к `1` (или выше), тем более случайный и разнообразный ответ.\n",
        "    * Например, значение `0.7` — баланс между креативностью и точностью.\n",
        "* `max_tokens` — ограничение на длину ответа модели (в токенах). Каждый токен приблизительно одно слово.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beed0df6-67b0-494e-a363-982198a1335e",
      "metadata": {
        "id": "beed0df6-67b0-494e-a363-982198a1335e"
      },
      "source": [
        "### Упражнения\n",
        "1. Разработать системный промпт, который на запрос пользователя возвращет суммаризацию запроса и ответ на заопрос.\n",
        "2. Разработать помпт, который на запрос пользователя всегда будет отчечать в стиле выбранного писателя.\n",
        "3. Проверить влияние температуры и длины ответа на его качество.\n",
        "4. Разработать промпт который будет на выходе давать  формат `JSON`, например\n",
        "```json\n",
        "{\n",
        "  \"defenition\": \"Prompt Engineering (инженерия подсказок) — это процесс разработки и оптимизации входных данных (подсказок) для языковых моделей искусственного интеллекта, направленный на получение максимально полезных и точных результатов от модели.\",\n",
        "  \"properties\": \"Четкость формулировки: запрос должен быть четко сформулированным и понятным модели. Контекстуальность: предоставление достаточного контекста помогает модели лучше понять задачу.Гибкость и итерационность: часто требуется несколько попыток\",\n",
        "  \"roles\": \"Пользователь: человек, задающий вопрос или требующий выполнения задачи, получающий результат работы модели. Модель: система искусственного интеллекта, принимающая запросы (подсказки), выполняющая обработку информации.\"\n",
        "}```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.SYSTEM,\n",
        "            content=(\n",
        "                \"\"\"\n",
        "                Ты полезный ассистент для тестирования ГигаЧата. Твоя задача отвечать в стиле выбранного писателя: Пушкин\n",
        "                ## Формат\n",
        "                Markdown\n",
        "                \"\"\"\n",
        "            )\n",
        "        ),\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        ),\n",
        "]"
      ],
      "metadata": {
        "id": "x56TQsQfP0B_"
      },
      "id": "x56TQsQfP0B_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "802d2dcd-f784-4125-a38b-f3a5322f852d",
      "metadata": {
        "id": "802d2dcd-f784-4125-a38b-f3a5322f852d"
      },
      "outputs": [],
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.SYSTEM,\n",
        "            content=(\n",
        "                \"\"\"\n",
        "                Ты полезный ассистент для тестирования ГигаЧата. Твоя задача отвечать студенту на учебные вопросы\n",
        "                Отвечай кратко и ёмко!\n",
        "                ## Шаблон ответа:\n",
        "                Запрос: {суммаризация запроса пользователя}.\n",
        "                Ответ: {ответ на запрос со списками, таблицами}.\n",
        "                Роли: {роли по информации запроса}.\n",
        "                ## Формат\n",
        "                Markdown\n",
        "                \"\"\"\n",
        "            )\n",
        "        ),\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.SYSTEM,\n",
        "            content=(\n",
        "                \"\"\"\n",
        "                Ты полезный ассистент для тестирования ГигаЧата. Твоя задача отвечать студенту на учебные вопросы\n",
        "                Отвечай кратко и ёмко!\n",
        "                ## Шаблон ответа:\n",
        "                {\n",
        "                  \"defenition\": \"\",\n",
        "                  \"properties\": \"\",\n",
        "                  \"roles\": \"\"\n",
        "                }\n",
        "                ## Формат\n",
        "                JSON\n",
        "                \"\"\"\n",
        "            )\n",
        "        ),\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        ),\n",
        "    ]"
      ],
      "metadata": {
        "id": "twj1-1ypgMKn"
      },
      "id": "twj1-1ypgMKn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ded0d7-c55d-43b3-82f8-8f6511106e24",
      "metadata": {
        "id": "f4ded0d7-c55d-43b3-82f8-8f6511106e24"
      },
      "outputs": [],
      "source": [
        "payload = Chat(\n",
        "    messages=messages,\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        ")\n",
        "\n",
        "response = model.chat(payload)\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8050f0b9-75b9-4ad2-83ad-c612346f4b94",
      "metadata": {
        "id": "8050f0b9-75b9-4ad2-83ad-c612346f4b94"
      },
      "source": [
        "# Функции и Актуализация запросов к модели\n",
        "\n",
        "Языковые модели, включая `GigaChat`, обучены на данных, зафиксированных до определённой даты. Они не знают, что происходит «здесь и сейчас».\n",
        "Но если дать модели возможность вызвать функцию, которая получит свежие данные (например, через поисковик), — она сможет дать актуальный и точный ответ.\n",
        "\n",
        "[Механизм вызова функций](https://habr.com/ru/articles/806627/) называется `Function Calling` — механизм, при котором модель:\n",
        "* Решает, нужно ли вызвать функцию.\n",
        "* Формирует структурированный запрос к функции (с аргументами).\n",
        "* Система выполняет функцию.\n",
        "* Результат возвращается модели, и она формулирует финальный ответ.\n",
        "\n",
        "\n",
        "__Другими словами__ при использовании `Function Calling` в запрос передаётся не только история сообщений, но и список доступных функций.\n",
        "Модель анализирует контекст и решает:\n",
        "Ответить сразу, или вернуть специальное сообщение с `function_call`. Во втором случае будет необходимо вызвать функцию и повторно запросить модель.\n",
        "\n",
        "> Отметим, что не все модели подддерживают `Function Calling`.\n",
        "\n",
        "Создадим функцию  `search_ddg`, которая использует библиотеку `ddgs` для получения актуальных результатов поиска.\n",
        "Где `ddgs` — это библиотека для поиска в `DuckDuckGo`. `DuckDuckGo` выбран, потому что он не требует API-ключа."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef4894e5-aebe-40dc-bda2-f6c99c839a68",
      "metadata": {
        "id": "ef4894e5-aebe-40dc-bda2-f6c99c839a68"
      },
      "outputs": [],
      "source": [
        "def search_ddg(search_query):\n",
        "    \"\"\"Поиск в DuckDuckGo.\n",
        "        Полезен, когда нужно ответить на вопросы о текущих событиях.\n",
        "        Входными данными должен быть поисковый запрос.\"\"\"\n",
        "    return DDGS().text(search_query, max_results=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2d015e-bf0f-4239-9aa0-b2955430b534",
      "metadata": {
        "id": "0a2d015e-bf0f-4239-9aa0-b2955430b534"
      },
      "outputs": [],
      "source": [
        "results = search_ddg(MESSAGE)\n",
        "print(results[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8759fdbc-0e1d-4869-97d6-292bf897c9a3",
      "metadata": {
        "id": "8759fdbc-0e1d-4869-97d6-292bf897c9a3"
      },
      "outputs": [],
      "source": [
        "search_func = Function(\n",
        "    name=\"duckduckgo_search\",\n",
        "    description=\"Поиск в DuckDuckGo для получения актуальной информации.\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\"query\": {\"type\": \"string\"}},\n",
        "        required=[\"query\"],\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4vbqWVKhSGkk"
      },
      "id": "4vbqWVKhSGkk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0da5d2fd-9e50-4286-8458-3d04fc662593",
      "metadata": {
        "id": "0da5d2fd-9e50-4286-8458-3d04fc662593"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "        Messages(role=MessagesRole.USER, content=MESSAGE)\n",
        "    ]\n",
        "chat = Chat(messages=messages, functions=[search_func])\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "print(message)\n",
        "resp.finish_reason"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d749f3-6904-43cf-a895-440fd1250010",
      "metadata": {
        "id": "b4d749f3-6904-43cf-a895-440fd1250010"
      },
      "outputs": [],
      "source": [
        "# Если модель хочет вызвать функцию\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func_name = message.function_call.name\n",
        "    query = message.function_call.arguments[\"query\"]\n",
        "\n",
        "    # Выполняем функцию\n",
        "    result = search_ddg(query)\n",
        "\n",
        "    # Шаг 2: отправляем результат обратно модели\n",
        "    messages.extend([\n",
        "        message,  # сообщение с function_call\n",
        "        Messages(role=MessagesRole.FUNCTION, content=json.dumps({\"result\": result}, ensure_ascii=False))\n",
        "    ])\n",
        "    final_resp = model.chat(Chat(messages=messages)).choices[0]\n",
        "    response = final_resp.message.content\n",
        "else:\n",
        "    # Модель ответила сразу\n",
        "    print('МОДЕЛЬ ОТВЕТИЛА СРАЗУ')\n",
        "    response = message.content\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "330c2c47-3f53-46e4-90f0-1e805f8b4213",
      "metadata": {
        "id": "330c2c47-3f53-46e4-90f0-1e805f8b4213"
      },
      "source": [
        "### Упражения\n",
        "1. Измените поле `desription` описания функции, например на\n",
        "    * \"Используй ТОЛЬКО для вопросов о погоде.\"\n",
        "    * \"Никогда не используй этот поиск.\"\n",
        "    * \"Это функция для поиска рецептов блюд.\"\n",
        "Проверьте как это скажется на результатах.\n",
        "2. Измените значение `max_results` в диапазоне 1 - 10, провеврьте как это скажется на качестве ответа\n",
        "3. Добавьте к примеру системный промпт, например \"Ты — помощник, который ВСЕГДА ищет информацию в интернете, даже если знаешь ответ.\"\n",
        "4. Добавьте функцию текущей даты к списку функций запроса.\n",
        "```python\n",
        "   def get_current_date():\n",
        "        \"\"\"Возвращает текущую дату в формате ГГГГ-ММ-ДД.\"\"\"\n",
        "        from datetime import datetime\n",
        "        return datetime.now().strftime(\"%Y-%m-%d\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_current_date():\n",
        "  from datetime import datetime\n",
        "  now = datetime.now()\n",
        "  today = datetime(year=now.year, month=now.month+1, day=5)\n",
        "  return today.strftime(\"%Y-%m-%d\")"
      ],
      "metadata": {
        "id": "a8VMnnDun0CY"
      },
      "id": "a8VMnnDun0CY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_current_date())"
      ],
      "metadata": {
        "id": "__jXjFNsn-GB"
      },
      "id": "__jXjFNsn-GB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_func = Function(\n",
        "    name=\"get_current_date\",\n",
        "    description=\"Узнать дату сегодня (сегодняшний день, сегодняшнее число)\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={},\n",
        "        required=[],\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "RoThkfp0oAnX"
      },
      "id": "RoThkfp0oAnX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_func = [\n",
        "    Function(\n",
        "      name=\"duckduckgo_search\",\n",
        "      description=\"Поиск в DuckDuckGo для получения актуальной информации. Используй ТОЛЬКО для погоды и даты\",\n",
        "      parameters=FunctionParameters(\n",
        "          type=\"object\",\n",
        "          properties={\"query\": {\"type\": \"string\"}},\n",
        "          required=[\"query\"],\n",
        "          )\n",
        "    ),\n",
        "    Fucntion(\n",
        "      name=\"get_current_date\",\n",
        "      description=\"Узнать дату сегодня (сегодняшний день, сегодняшнее число)\",\n",
        "      parameters=FunctionParameters(\n",
        "          type=\"object\",\n",
        "          properties={},\n",
        "          required=[],\n",
        "        ),\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "W6jgnXjYmJ-7"
      },
      "id": "W6jgnXjYmJ-7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8350c04-5208-4cf8-95d7-ecd64e3db3b3",
      "metadata": {
        "id": "e8350c04-5208-4cf8-95d7-ecd64e3db3b3"
      },
      "outputs": [],
      "source": [
        "MESSAGE = \"Какое сегодня число?\"\n",
        "\n",
        "messages = [\n",
        "        Messages(role=MessagesRole.USER, content=MESSAGE)\n",
        "    ]\n",
        "\n",
        "chat = Chat(messages=messages, functions=search_func, max_tokens=100)\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "print(message)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Если модель хочет вызвать функцию\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func_name = message.function_call.name\n",
        "\n",
        "    # Выполняем функцию\n",
        "    if func_name == \"duckduckgo_search\":\n",
        "      query = message.function_call.arguments[\"query\"]\n",
        "      result = search_ddg(query)\n",
        "    elif func_name == \"get_current_date\":\n",
        "      result = get_current_date()\n",
        "\n",
        "    # Шаг 2: отправляем результат обратно модели\n",
        "    messages.extend([\n",
        "        message,  # сообщение с function_call\n",
        "        Messages(role=MessagesRole.FUNCTION, content=json.dumps({\"result\": result}, ensure_ascii=False))\n",
        "    ])\n",
        "    final_resp = model.chat(Chat(messages=messages)).choices[0]\n",
        "    response = final_resp.message.content\n",
        "else:\n",
        "    # Модель ответила сразу\n",
        "    print('МОДЕЛЬ ОТВЕТИЛА СРАЗУ')\n",
        "    response = message.content\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response))"
      ],
      "metadata": {
        "id": "T4j4F5JMoVFF"
      },
      "id": "T4j4F5JMoVFF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4778da43-9f46-49e8-8c6b-dcbeab29fa6a",
      "metadata": {
        "id": "4778da43-9f46-49e8-8c6b-dcbeab29fa6a"
      },
      "source": [
        "## Упражения 2\n",
        "\n",
        "Создадим свой калькулятор при помощи функций `GigaChat`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dda6449-cdb8-422e-923d-329572489166",
      "metadata": {
        "id": "6dda6449-cdb8-422e-923d-329572489166"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def safe_calculate(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Выполняет математическое выражение.\n",
        "    Поддерживает: +, -, *, /, **, скобки, числа с точкой.\n",
        "    Безопасен: разрешает ТОЛЬКО математические символы.\n",
        "    \"\"\"\n",
        "    # Разрешённые символы: цифры, операторы, скобки, точка, пробелы\n",
        "    if not re.fullmatch(r'[\\d+\\-*/().\\s]+', expression):\n",
        "        return \"Ошибка: выражение содержит недопустимые символы.\"\n",
        "\n",
        "    try:\n",
        "        # Ограничиваем сложность (например, не даём выполнить 9**9**9)\n",
        "        if '^' in expression or len(expression) > 50:\n",
        "            return \"Ошибка: выражение слишком сложное или длинное.\"\n",
        "\n",
        "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
        "        return str(result)\n",
        "    except Exception as e:\n",
        "        return f\"Ошибка вычисления: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4387a9e3-15cc-416e-bd0d-87107b8f7178",
      "metadata": {
        "id": "4387a9e3-15cc-416e-bd0d-87107b8f7178"
      },
      "outputs": [],
      "source": [
        "safe_calculate('3*(4+5)**2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ccfa93f-9a97-41fb-ae91-7acca80eadb6",
      "metadata": {
        "id": "7ccfa93f-9a97-41fb-ae91-7acca80eadb6"
      },
      "outputs": [],
      "source": [
        "calculate_func = Function(\n",
        "    name=\"calculate\",\n",
        "    description=\"Выполняет математические вычисления. Передавай ТОЛЬКО выражение в виде строки, например: '2 + 3 * 4'.\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\n",
        "            \"expression\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Математическое выражение (только цифры, +, -, *, /, **, скобки)\"\n",
        "            }\n",
        "        },\n",
        "        required=[\"expression\"],\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01bbf602-9bf9-421e-aeab-cb882584e722",
      "metadata": {
        "id": "01bbf602-9bf9-421e-aeab-cb882584e722"
      },
      "outputs": [],
      "source": [
        "message = 'Сколько будет 3*(4+5)**2'\n",
        "\n",
        "messages = [\n",
        "    Messages(role=MessagesRole.USER, content=message)\n",
        "]\n",
        "\n",
        "chat = Chat(messages=messages, functions=[calculate_func])\n",
        "\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func = message.function_call\n",
        "    if func.name == \"calculate\":\n",
        "        expr = func.arguments.get(\"expression\", \"\")\n",
        "        result = safe_calculate(expr)\n",
        "        # Возвращаем результат модели\n",
        "        messages.extend([\n",
        "            message,\n",
        "            Messages(role=MessagesRole.FUNCTION, content=result)\n",
        "        ])\n",
        "        # Получаем финальный ответ\n",
        "        final = model.chat(Chat(messages=messages)).choices[0]\n",
        "        response =  final.message.content\n",
        "else:\n",
        "    # Модель ответила без вычислений (например, объяснила задачу)\n",
        "    response = message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f920ef5-e42d-4419-957e-66ce8b60cd75",
      "metadata": {
        "id": "3f920ef5-e42d-4419-957e-66ce8b60cd75"
      },
      "outputs": [],
      "source": [
        "display(Markdown(\"<blockquote>\\n\\n\"+response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b42ecb18-022c-4307-8c63-a431b8213837",
      "metadata": {
        "id": "b42ecb18-022c-4307-8c63-a431b8213837"
      },
      "source": [
        "__Упражения__\n",
        "1. Сделайте проверку на sin/cos в функции калькулятора\n",
        "   \n",
        "2. Расширьте функционал калькулятора"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_func = Function(\n",
        "    name=\"calculate\",\n",
        "    description=\"Выполняет математические вычисления. Передавай ТОЛЬКО выражение в виде строки, например: '2 + 3 * 4'.\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\n",
        "            \"expression\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Математическое выражение (только цифры, +, -, *, /, **, скобки)\"\n",
        "            }\n",
        "        },\n",
        "        required=[\"expression\"],\n",
        "    )\n",
        ")\n",
        "\n",
        "sin_func = Function(\n",
        "    name=\"sin\",\n",
        "    description=\"Находит синус выражения. ВАЖНО, сначала высчитай синусы, потом замени синусы на реальные значения и передай аргумент функции калькулятора\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\n",
        "            \"value\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Значение угла в радианах\"\n",
        "            }\n",
        "        },\n",
        "        required=[\"value\"],\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "kZza6pPdsU2s"
      },
      "id": "kZza6pPdsU2s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = 'Сколько будет 55*243?'\n",
        "\n",
        "messages = [\n",
        "    Messages(role=MessagesRole.USER, content=message)\n",
        "]\n",
        "\n",
        "chat = Chat(messages=messages, functions=[calculate_func, sin_func], max_tokens=100)\n",
        "\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func = message.function_call\n",
        "    if func.name == \"calculate\":\n",
        "        print(\"Калькулирую!\")\n",
        "        expr = func.arguments.get(\"expression\", \"\")\n",
        "        result = safe_calculate(expr)\n",
        "    elif func.name == \"sin\":\n",
        "        value = func.arguments.get(\"value\", \"\")\n",
        "        print(\"Расчёты!\")\n",
        "        result = eval(f\"sin({value})\")\n",
        "    # Возвращаем результат модели\n",
        "    messages.extend([\n",
        "        message,\n",
        "        Messages(role=MessagesRole.FUNCTION, content=result)\n",
        "    ])\n",
        "    # Получаем финальный ответ\n",
        "    final = model.chat(Chat(messages=messages)).choices[0]\n",
        "    response =  final.message.content\n",
        "else:\n",
        "    # Модель ответила без вычислений (например, объяснила задачу)\n",
        "    response = message.content"
      ],
      "metadata": {
        "id": "GICchSqBs-Qp"
      },
      "id": "GICchSqBs-Qp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "PQJ0J2k9vD3N"
      },
      "id": "PQJ0J2k9vD3N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d09d2294-0782-460f-bfdc-dc3cd52c125f",
      "metadata": {
        "id": "d09d2294-0782-460f-bfdc-dc3cd52c125f"
      },
      "outputs": [],
      "source": [
        "from math import sin, cos, pi\n",
        "print(sin(3*pi/2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de6e24ea-1c04-4a74-bf83-9d69a5adf892",
      "metadata": {
        "id": "de6e24ea-1c04-4a74-bf83-9d69a5adf892"
      },
      "source": [
        "# <span style=\"color:red\">Опционально.</span> О более продвинутом пути к LLM-приложениям"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_gigachat"
      ],
      "metadata": {
        "id": "q36DqYcbxDZA",
        "collapsed": true
      },
      "id": "q36DqYcbxDZA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "j9819xjLxfRu",
        "collapsed": true
      },
      "id": "j9819xjLxfRu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community"
      ],
      "metadata": {
        "id": "cBbVejG6jN3V",
        "collapsed": true
      },
      "id": "cBbVejG6jN3V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57a311e9-7a90-4aef-801e-010ec53b3e89",
      "metadata": {
        "id": "57a311e9-7a90-4aef-801e-010ec53b3e89"
      },
      "outputs": [],
      "source": [
        "from langchain_gigachat import GigaChat\n",
        "# from langchain_core.tools import tool\n",
        "# from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, FunctionMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219a10ac-9507-43eb-90f8-9143b709ded6",
      "metadata": {
        "id": "219a10ac-9507-43eb-90f8-9143b709ded6"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62cc963b-0bd4-4683-b651-16903e4bdb0f",
      "metadata": {
        "id": "62cc963b-0bd4-4683-b651-16903e4bdb0f"
      },
      "outputs": [],
      "source": [
        "# Инициализация модели\n",
        "llm = GigaChat(\n",
        "    model=\"GigaChat-2\",\n",
        "    credentials=auth,\n",
        "    verify_ssl_certs=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1930148-9153-4ad6-8acb-89f101e98a13",
      "metadata": {
        "id": "a1930148-9153-4ad6-8acb-89f101e98a13"
      },
      "source": [
        "В `Langchain` есть классы `HumanMessage`, `SystemMessage` и `AssistantMessage` для удобного представления словарей сообщений.\n",
        "\n",
        "Например вмето записи сообщания в стиле:\n",
        "```json\n",
        "{'role': 'system',\n",
        "'content': 'Отвечай как бывалый пират. Пусть тебя зовут Генри Морган.'\n",
        "}\n",
        "```\n",
        "теперь можем записать:\n",
        "```python\n",
        "SystemMessage(content='Отвечай как бывалый пират. Пусть тебя зовут Генри Морган.')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812ee915-ffd2-405f-acda-fedcf7fb476d",
      "metadata": {
        "id": "812ee915-ffd2-405f-acda-fedcf7fb476d"
      },
      "outputs": [],
      "source": [
        "msg = [SystemMessage(content='Отвечай как инженр-датасаинтист с 20 летним опытом. Используй Markdown разметку ответа. Ответ не должен быть длинее 10 строк')]\n",
        "\n",
        "question = \"Какие приемущества может дать langchain в работе с GigaChat\"\n",
        "\n",
        "msg.append(HumanMessage(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396a1ef5-a52c-459e-9ec8-0b1f1e6ca97d",
      "metadata": {
        "scrolled": true,
        "id": "396a1ef5-a52c-459e-9ec8-0b1f1e6ca97d"
      },
      "outputs": [],
      "source": [
        "results = llm.invoke(msg).content[:600]\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+results))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e36f412e-86b4-46d9-8283-db22049ef71a",
      "metadata": {
        "id": "e36f412e-86b4-46d9-8283-db22049ef71a"
      },
      "source": [
        "При помощи класса `AIMessage` `LangChain` позволяет сохранить ответ на первое сообщение и использовать этот результат при вторичном запросе. В нашем случае попросим уточнить `GigaChat` примеры кода для нашего запроса.\n",
        "\n",
        "В примере будем использовать метод `invoke` - часть унифицированного `Runnable API (LangChain 0.1.0+)`.\n",
        "Прямой вызов - устаревший подход, может быть удален в будущем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b7d1357-6954-4d58-9b10-92b6d57314e5",
      "metadata": {
        "scrolled": true,
        "id": "9b7d1357-6954-4d58-9b10-92b6d57314e5",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Получаем ответ\n",
        "response = llm.invoke(msg)  # Используем invoke вместо прямого вызова\n",
        "results = response.content[:600]\n",
        "\n",
        "# Сохраняем ответ в историю\n",
        "msg.append(AIMessage(content=results))\n",
        "\n",
        "# Пример продолжения диалога с историей\n",
        "follow_up_question = \"Можешь привести конкретный пример использования цепочки (chain) с GigaChat (langchain_gigachat)?\"\n",
        "msg.append(HumanMessage(content=follow_up_question))\n",
        "\n",
        "# Получаем ответ с учетом всей истории\n",
        "follow_up_response = llm.invoke(msg)\n",
        "msg.append(AIMessage(content=follow_up_response.content))\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+follow_up_response.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "502c9b23-24bc-4ca2-ab8f-0fa4b91c9fcf",
      "metadata": {
        "id": "502c9b23-24bc-4ca2-ab8f-0fa4b91c9fcf"
      },
      "source": [
        "Попробуем также в целях демонстрации возможностей `langchain` создать цепочку рассуджений. Для этого воспользуемся специальным классом `PromptTemplate`, который позволяет создавать шаблоны запросов аналогично f-функциям"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "662eef72-9eba-4ddf-b8fe-405355191356",
      "metadata": {
        "id": "662eef72-9eba-4ddf-b8fe-405355191356",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Создаем шаблон для Chain of Thought\n",
        "cot_template = \"\"\"\n",
        "Реши задачу шаг за шагом:\n",
        "\n",
        "Задача: {problem}\n",
        "\n",
        "Пожалуйста:\n",
        "1. Сначала пойми, что дано и что нужно найти\n",
        "2. Разбей решение на логические шаги\n",
        "3. Выполни вычисления для каждого шага\n",
        "4. Проверь правильность рассуждений\n",
        "5. Сформулируй окончательный ответ\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cot_prompt = ChatPromptTemplate.from_template(\n",
        "    cot_template\n",
        ")\n",
        "\n",
        "cot_chain = cot_prompt | llm  # создание цепочки через pipe\n",
        "\n",
        "# Создаем цепочку\n",
        "# cot_chain = LLMChain(llm=llm, prompt=cot_prompt)\n",
        "# news = \"Вчера в Екатеринбурге произошло 3 ДТП и прорвало трубу на Ленина.\"\n",
        "# response = cot_chain.invoke({\"news_text\": news})\n",
        "# print(response.content)\n",
        "\n",
        "# Используем\n",
        "problems = [\n",
        "    \"В классе 30 учеников. 40% из них - девочки. Сколько мальчиков в классе?\",\n",
        "    \"Книга стоит 500 рублей. После скидки цена снизилась на 20%. Сколько стоит книга после скидки?\",\n",
        "]\n",
        "\n",
        "for problem in problems:\n",
        "    result = cot_chain.invoke(problem)\n",
        "    display(Markdown(f\"**Задача:\\n** {problem}\\n----------------------------\"))\n",
        "    display(Markdown(f\"**Решение:\\n\\n** {result}\"))\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dbd67a2-b43b-48f9-92fc-6606809084e8",
      "metadata": {
        "id": "9dbd67a2-b43b-48f9-92fc-6606809084e8"
      },
      "source": [
        "### Упражнение:\n",
        "\n",
        "Проверьте качество работы цепочки рассуждений для разных категорий вопросов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca45eef-48b9-46e2-be61-877e56d11b06",
      "metadata": {
        "id": "fca45eef-48b9-46e2-be61-877e56d11b06",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "problems = [\n",
        "    \"Каков радиус Земли?\"\n",
        "]\n",
        "\n",
        "for problem in problems:\n",
        "    result = cot_chain.invoke(problem)\n",
        "    display(Markdown(f\"**Задача:\\n** {problem}\\n----------------------------\"))\n",
        "    display(Markdown(result.content))\n",
        "    print(\"---\")\n",
        "\n",
        "problems = [\n",
        "    \"Рецепт пельменей\"\n",
        "]\n",
        "\n",
        "for problem in problems:\n",
        "    result = cot_chain.invoke(problem)\n",
        "    display(Markdown(f\"**Задача:\\n** {problem}\\n----------------------------\"))\n",
        "    display(Markdown(result.content))\n",
        "    print(\"---\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}